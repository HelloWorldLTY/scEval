{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f7d296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/scanpy/_settings.py:447: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n",
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:70: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hxq4upxg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:82: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2559a47892694cef8490ab6b811fa63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-lake-1544</strong> at: <a href='https://wandb.ai/zhao-lab/scGPT/runs/hxq4upxg' target=\"_blank\">https://wandb.ai/zhao-lab/scGPT/runs/hxq4upxg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230726_222429-hxq4upxg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hxq4upxg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:82: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af142c724cb4b8d8a2e401a47638514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668583204348882, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:70: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/gpfs/gibbs/pi/zhao/tl688/scGPT/examples/wandb/run-20230726_222737-xmf2rmnu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zhao-lab/scGPT/runs/xmf2rmnu' target=\"_blank\">revived-feather-1545</a></strong> to <a href='https://wandb.ai/zhao-lab/scGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zhao-lab/scGPT' target=\"_blank\">https://wandb.ai/zhao-lab/scGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zhao-lab/scGPT/runs/xmf2rmnu' target=\"_blank\">https://wandb.ai/zhao-lab/scGPT/runs/xmf2rmnu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'dataset_name': 'PBMC_10K', 'do_train': True, 'load_model': 'save/scGPT_bc', 'mask_ratio': 0.4, 'epochs': 1, 'n_bins': 51, 'GEPC': True, 'ecs_thres': 0.8, 'dab_weight': 1.0, 'lr': 0.0001, 'batch_size': 32, 'layer_size': 128, 'nlayers': 4, 'nhead': 4, 'dropout': 0.2, 'schedule_ratio': 0.9, 'save_eval_interval': 5, 'log_interval': 100, 'fast_transformer': True, 'pre_norm': False, 'amp': True}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import numpy as npddddd\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "from Sophia import SophiaG \n",
    "\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    "    masked_ce_loss\n",
    ")\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "# from functions_group import DistanceLoss\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "# os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "# hyperparameter_defaults = dict(\n",
    "#     seed=42,\n",
    "#     dataset_name=\"PBMC_10K\",\n",
    "#     do_train=True,\n",
    "#     load_model=\"save/scGPT_bc\",\n",
    "#     mask_ratio=0.1,\n",
    "#     epochs=10,\n",
    "#     n_bins=10001,\n",
    "#     GEPC=True,  # Masked value prediction for cell embedding\n",
    "#     ecs_thres=0.8,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "#     dab_weight=10.0,\n",
    "#     lr=1e-4,\n",
    "#     batch_size=64,\n",
    "#     layer_size=128,\n",
    "#     nlayers=4,\n",
    "#     nhead=4,\n",
    "#     # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "#     dropout=0.2,\n",
    "#     schedule_ratio=0.9,  # ratio of epochs for learning rate schedule\n",
    "#     save_eval_interval=5,\n",
    "#     log_interval=10,\n",
    "#     fast_transformer=True,\n",
    "#     pre_norm=False,\n",
    "#     amp=True,  # Automatic Mixed Precision\n",
    "# )\n",
    "\n",
    "# modify original param\n",
    "hyperparameter_defaults = dict(\n",
    "    seed=42,\n",
    "    dataset_name=\"PBMC_10K\",\n",
    "    do_train=True,\n",
    "    load_model=\"save/scGPT_bc\",\n",
    "    mask_ratio=0.4,\n",
    "    epochs=1,\n",
    "    n_bins=51,\n",
    "    GEPC=True,  # Masked value prediction for cell embedding\n",
    "    ecs_thres=0.8,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=1.0,\n",
    "    lr=1e-4,\n",
    "    batch_size=32,\n",
    "    layer_size=128,\n",
    "    nlayers=4,\n",
    "    nhead=4,\n",
    "    # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "    dropout=0.2,\n",
    "    schedule_ratio=0.9,  # ratio of epochs for learning rate schedule\n",
    "    save_eval_interval=5,\n",
    "    log_interval=100,\n",
    "    fast_transformer=True,\n",
    "    pre_norm=False,\n",
    "    amp=True,  # Automatic Mixed Precision\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e920b5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 324 × 16562\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'cluster_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'spatial', 'umap'\n",
      "    obsm: 'X_pca', 'X_umap', 'spatial'\n",
      "    varm: 'PCs'\n",
      "    obsp: 'connectivities', 'distances'\n",
      "scGPT - INFO - match 13444/16562 genes in vocabulary of size 36574.\n",
      "scGPT - INFO - Resume model from save/scGPT_bc/best_model.pt, the model args will override the config save/scGPT_bc/args.json.\n"
     ]
    }
   ],
   "source": [
    "# adata = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/tangram/ST-LN-compressed.h5ad\")\n",
    "adata = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/scGPT/examples/mouse_spatial.h5ad\")\n",
    "print(adata)\n",
    "\n",
    "ori_batch_col = \"batch\"\n",
    "adata.obs['batch'] = list(adata.obs['in_tissue'])\n",
    "adata.obs['celltype'] = list(adata.obs['cluster'])\n",
    "adata.obs[\"celltype\"] = adata.obs[\"celltype\"].astype(\"category\")\n",
    "adata.var_names = [i.upper() for i in adata.var_names]\n",
    "data_is_raw = True\n",
    "\n",
    "\n",
    "# %%\n",
    "# make the batch category column \n",
    "adata.obs[\"str_batch\"] = adata.obs[ori_batch_col].astype(str)\n",
    "batch_id_labels = adata.obs[\"str_batch\"].astype(\"category\").cat.codes.values\n",
    "adata.obs[\"batch_id\"] = batch_id_labels\n",
    "\n",
    "adata.var[\"gene_name\"] = adata.var.index.tolist()\n",
    "\n",
    "if config.load_model is not None:\n",
    "    model_dir = Path(config.load_model)\n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / \"best_model.pt\"\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "    logger.info(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]\n",
    "\n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    logger.info(\n",
    "        f\"Resume model from {model_file}, the model args will override the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9fe49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_tissue</th>\n",
       "      <th>array_row</th>\n",
       "      <th>array_col</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>log1p_n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "      <th>pct_counts_in_top_50_genes</th>\n",
       "      <th>pct_counts_in_top_100_genes</th>\n",
       "      <th>pct_counts_in_top_200_genes</th>\n",
       "      <th>...</th>\n",
       "      <th>total_counts_MT</th>\n",
       "      <th>log1p_total_counts_MT</th>\n",
       "      <th>pct_counts_MT</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>leiden</th>\n",
       "      <th>cluster</th>\n",
       "      <th>batch</th>\n",
       "      <th>celltype</th>\n",
       "      <th>str_batch</th>\n",
       "      <th>batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAATGGCATGTCTTGT-1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>5191</td>\n",
       "      <td>8.554874</td>\n",
       "      <td>15977.0</td>\n",
       "      <td>9.678968</td>\n",
       "      <td>20.629655</td>\n",
       "      <td>26.757213</td>\n",
       "      <td>34.743694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15977.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAACTGGTAGTTGC-1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>5252</td>\n",
       "      <td>8.566555</td>\n",
       "      <td>16649.0</td>\n",
       "      <td>9.720165</td>\n",
       "      <td>20.481711</td>\n",
       "      <td>26.277855</td>\n",
       "      <td>34.092138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16649.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAGGAAATCGAATA-1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>6320</td>\n",
       "      <td>8.751633</td>\n",
       "      <td>23375.0</td>\n",
       "      <td>10.059465</td>\n",
       "      <td>17.929412</td>\n",
       "      <td>23.850267</td>\n",
       "      <td>32.077005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23375.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACCCAGAGACGGAGA-1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>3659</td>\n",
       "      <td>8.205218</td>\n",
       "      <td>9229.0</td>\n",
       "      <td>9.130215</td>\n",
       "      <td>25.939972</td>\n",
       "      <td>31.964460</td>\n",
       "      <td>39.885145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9229.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACCGTTGTGTTTGCT-1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>4512</td>\n",
       "      <td>8.414717</td>\n",
       "      <td>12679.0</td>\n",
       "      <td>9.447782</td>\n",
       "      <td>21.839262</td>\n",
       "      <td>28.038489</td>\n",
       "      <td>36.209480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12679.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGGATTGGGTACCAC-1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>4980</td>\n",
       "      <td>8.513386</td>\n",
       "      <td>15381.0</td>\n",
       "      <td>9.640953</td>\n",
       "      <td>21.038944</td>\n",
       "      <td>27.059359</td>\n",
       "      <td>35.114752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15381.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGGCTCGCATGAGAC-1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>4620</td>\n",
       "      <td>8.438366</td>\n",
       "      <td>13193.0</td>\n",
       "      <td>9.487517</td>\n",
       "      <td>20.609414</td>\n",
       "      <td>26.445842</td>\n",
       "      <td>34.063519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13193.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Cortex_3</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGTATCACACAGAAT-1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>6120</td>\n",
       "      <td>8.719481</td>\n",
       "      <td>21951.0</td>\n",
       "      <td>9.996614</td>\n",
       "      <td>18.199626</td>\n",
       "      <td>24.235798</td>\n",
       "      <td>32.440436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21951.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGTGGCCCTGACAGT-1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>4971</td>\n",
       "      <td>8.511577</td>\n",
       "      <td>14779.0</td>\n",
       "      <td>9.601030</td>\n",
       "      <td>21.381690</td>\n",
       "      <td>27.924758</td>\n",
       "      <td>36.213546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14779.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGTTAGCAAATTCGA-1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>4820</td>\n",
       "      <td>8.480737</td>\n",
       "      <td>14396.0</td>\n",
       "      <td>9.574775</td>\n",
       "      <td>20.595999</td>\n",
       "      <td>26.674076</td>\n",
       "      <td>34.655460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14396.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Cortex_3</td>\n",
       "      <td>1</td>\n",
       "      <td>Cortex_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    in_tissue  array_row  array_col  n_genes_by_counts  \\\n",
       "AAATGGCATGTCTTGT-1          1         13         69               5191   \n",
       "AACAACTGGTAGTTGC-1          1         28         42               5252   \n",
       "AACAGGAAATCGAATA-1          1         15         67               6320   \n",
       "AACCCAGAGACGGAGA-1          1         15         39               3659   \n",
       "AACCGTTGTGTTTGCT-1          1         12         64               4512   \n",
       "...                       ...        ...        ...                ...   \n",
       "TTGGATTGGGTACCAC-1          1         17         55               4980   \n",
       "TTGGCTCGCATGAGAC-1          1         23         37               4620   \n",
       "TTGTATCACACAGAAT-1          1         12         74               6120   \n",
       "TTGTGGCCCTGACAGT-1          1         18         60               4971   \n",
       "TTGTTAGCAAATTCGA-1          1         22         42               4820   \n",
       "\n",
       "                    log1p_n_genes_by_counts  total_counts  log1p_total_counts  \\\n",
       "AAATGGCATGTCTTGT-1                 8.554874       15977.0            9.678968   \n",
       "AACAACTGGTAGTTGC-1                 8.566555       16649.0            9.720165   \n",
       "AACAGGAAATCGAATA-1                 8.751633       23375.0           10.059465   \n",
       "AACCCAGAGACGGAGA-1                 8.205218        9229.0            9.130215   \n",
       "AACCGTTGTGTTTGCT-1                 8.414717       12679.0            9.447782   \n",
       "...                                     ...           ...                 ...   \n",
       "TTGGATTGGGTACCAC-1                 8.513386       15381.0            9.640953   \n",
       "TTGGCTCGCATGAGAC-1                 8.438366       13193.0            9.487517   \n",
       "TTGTATCACACAGAAT-1                 8.719481       21951.0            9.996614   \n",
       "TTGTGGCCCTGACAGT-1                 8.511577       14779.0            9.601030   \n",
       "TTGTTAGCAAATTCGA-1                 8.480737       14396.0            9.574775   \n",
       "\n",
       "                    pct_counts_in_top_50_genes  pct_counts_in_top_100_genes  \\\n",
       "AAATGGCATGTCTTGT-1                   20.629655                    26.757213   \n",
       "AACAACTGGTAGTTGC-1                   20.481711                    26.277855   \n",
       "AACAGGAAATCGAATA-1                   17.929412                    23.850267   \n",
       "AACCCAGAGACGGAGA-1                   25.939972                    31.964460   \n",
       "AACCGTTGTGTTTGCT-1                   21.839262                    28.038489   \n",
       "...                                        ...                          ...   \n",
       "TTGGATTGGGTACCAC-1                   21.038944                    27.059359   \n",
       "TTGGCTCGCATGAGAC-1                   20.609414                    26.445842   \n",
       "TTGTATCACACAGAAT-1                   18.199626                    24.235798   \n",
       "TTGTGGCCCTGACAGT-1                   21.381690                    27.924758   \n",
       "TTGTTAGCAAATTCGA-1                   20.595999                    26.674076   \n",
       "\n",
       "                    pct_counts_in_top_200_genes  ...  total_counts_MT  \\\n",
       "AAATGGCATGTCTTGT-1                    34.743694  ...              0.0   \n",
       "AACAACTGGTAGTTGC-1                    34.092138  ...              0.0   \n",
       "AACAGGAAATCGAATA-1                    32.077005  ...              0.0   \n",
       "AACCCAGAGACGGAGA-1                    39.885145  ...              0.0   \n",
       "AACCGTTGTGTTTGCT-1                    36.209480  ...              0.0   \n",
       "...                                         ...  ...              ...   \n",
       "TTGGATTGGGTACCAC-1                    35.114752  ...              0.0   \n",
       "TTGGCTCGCATGAGAC-1                    34.063519  ...              0.0   \n",
       "TTGTATCACACAGAAT-1                    32.440436  ...              0.0   \n",
       "TTGTGGCCCTGACAGT-1                    36.213546  ...              0.0   \n",
       "TTGTTAGCAAATTCGA-1                    34.655460  ...              0.0   \n",
       "\n",
       "                    log1p_total_counts_MT  pct_counts_MT  n_counts  leiden  \\\n",
       "AAATGGCATGTCTTGT-1                    0.0            0.0   15977.0       0   \n",
       "AACAACTGGTAGTTGC-1                    0.0            0.0   16649.0       0   \n",
       "AACAGGAAATCGAATA-1                    0.0            0.0   23375.0       0   \n",
       "AACCCAGAGACGGAGA-1                    0.0            0.0    9229.0       1   \n",
       "AACCGTTGTGTTTGCT-1                    0.0            0.0   12679.0       0   \n",
       "...                                   ...            ...       ...     ...   \n",
       "TTGGATTGGGTACCAC-1                    0.0            0.0   15381.0       0   \n",
       "TTGGCTCGCATGAGAC-1                    0.0            0.0   13193.0       5   \n",
       "TTGTATCACACAGAAT-1                    0.0            0.0   21951.0       0   \n",
       "TTGTGGCCCTGACAGT-1                    0.0            0.0   14779.0       0   \n",
       "TTGTTAGCAAATTCGA-1                    0.0            0.0   14396.0       5   \n",
       "\n",
       "                     cluster batch  celltype str_batch batch_id  \n",
       "AAATGGCATGTCTTGT-1  Cortex_1     1  Cortex_1         1        0  \n",
       "AACAACTGGTAGTTGC-1  Cortex_1     1  Cortex_1         1        0  \n",
       "AACAGGAAATCGAATA-1  Cortex_1     1  Cortex_1         1        0  \n",
       "AACCCAGAGACGGAGA-1  Cortex_2     1  Cortex_2         1        0  \n",
       "AACCGTTGTGTTTGCT-1  Cortex_1     1  Cortex_1         1        0  \n",
       "...                      ...   ...       ...       ...      ...  \n",
       "TTGGATTGGGTACCAC-1  Cortex_1     1  Cortex_1         1        0  \n",
       "TTGGCTCGCATGAGAC-1  Cortex_3     1  Cortex_3         1        0  \n",
       "TTGTATCACACAGAAT-1  Cortex_1     1  Cortex_1         1        0  \n",
       "TTGTGGCCCTGACAGT-1  Cortex_1     1  Cortex_1         1        0  \n",
       "TTGTTAGCAAATTCGA-1  Cortex_3     1  Cortex_3         1        0  \n",
       "\n",
       "[324 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b27d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n",
      "scGPT - INFO - Filtering cells by counts ...\n",
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Log1p transforming ...\n",
      "scGPT - WARNING - The input data seems to be already log1p transformed. Set `log1p=False` to avoid double log1p transform.\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:249: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var['n_counts'] = number\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=3,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=\"batch\" if dataset_name != \"heart_cell\" else None)\n",
    "\n",
    "# %%\n",
    "if per_seq_batch_sample:\n",
    "    # sort the adata by batch_id in advance\n",
    "    adata_sorted = adata[adata.obs[\"batch_id\"].argsort()].copy()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Tokenize input\n",
    "\n",
    "# %%\n",
    "input_layer_key = \"X_binned\"\n",
    "all_counts = (\n",
    "    adata.layers[input_layer_key].A\n",
    "    if issparse(adata.layers[input_layer_key])\n",
    "    else adata.layers[input_layer_key]\n",
    ")\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "celltypes_labels = adata.obs[\"celltype\"].tolist()  # make sure count from 0\n",
    "num_types = len(set(celltypes_labels))\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata.obs[\"batch_id\"].tolist()\n",
    "num_batch_types = len(set(batch_ids))\n",
    "batch_ids = np.array(batch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6460cdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 324 × 11968\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster', 'batch', 'celltype', 'str_batch', 'batch_id'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'gene_name', 'id_in_vocab', 'n_counts'\n",
       "    uns: 'cluster_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'spatial', 'umap', 'log1p'\n",
       "    obsm: 'X_pca', 'X_umap', 'spatial', 'bin_edges'\n",
       "    varm: 'PCs'\n",
       "    layers: 'X_normed', 'X_log1p', 'X_binned'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67c332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to save/dev_PBMC_10K-Jul26-22-27\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# settings for input and preprocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = -1\n",
    "pad_value = -2\n",
    "n_input_bins = config.n_bins\n",
    "\n",
    "n_hvg = len(adata.var_names)  # number of highly variable genes\n",
    "max_seq_len = n_hvg + 1\n",
    "per_seq_batch_sample = False\n",
    "DSBN = True  # Domain-spec batchnorm\n",
    "explicit_zero_prob = True  # whether explicit bernoulli for zeros\n",
    "\n",
    "# %%\n",
    "dataset_name = config.dataset_name\n",
    "save_dir = Path(f\"./save/dev_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"save to {save_dir}\")\n",
    "# save the whole script to the dir\n",
    "# os.system(f\"cp {__file__} {save_dir}\")\n",
    "\n",
    "logger = scg.logger\n",
    "scg.utils.add_file_handler(logger, save_dir / \"run.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7697fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "input_layer_key = \"X_binned\"\n",
    "all_counts = (\n",
    "    adata.layers[input_layer_key].A\n",
    "    if issparse(adata.layers[input_layer_key])\n",
    "    else adata.layers[input_layer_key]\n",
    ")\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "celltypes_labels = adata.obs[\"celltype\"].tolist()  # make sure count from 0\n",
    "num_types = len(set(celltypes_labels))\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata.obs[\"batch_id\"].tolist()\n",
    "num_batch_types = len(set(batch_ids))\n",
    "batch_ids = np.array(batch_ids)\n",
    "\n",
    "(\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_celltype_labels,\n",
    "    valid_celltype_labels,\n",
    "    train_batch_labels,\n",
    "    valid_batch_labels,\n",
    ") = train_test_split(\n",
    "    all_counts, celltypes_labels, batch_ids, test_size=0.001, shuffle=True\n",
    ")\n",
    "\n",
    "# %%\n",
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27754159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - train set number of samples: 323, \n",
      "\t feature length: 11969\n",
      "scGPT - INFO - valid set number of samples: 1, \n",
      "\t feature length: 11969\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)\n",
    "\n",
    "# %%\n",
    "tokenized_train = tokenize_and_pad_batch(\n",
    "    train_data,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=True,\n",
    ")\n",
    "tokenized_valid = tokenize_and_pad_batch(\n",
    "    valid_data,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,\n",
    "    include_zero_gene=True,\n",
    ")\n",
    "logger.info(\n",
    "    f\"train set number of samples: {tokenized_train['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_train['genes'].shape[1]}\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"valid set number of samples: {tokenized_valid['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_valid['genes'].shape[1]}\"\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "def prepare_data(sort_seq_batch=False) -> Tuple[Dict[str, torch.Tensor]]:\n",
    "    masked_values_train = random_mask_value(\n",
    "        tokenized_train[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    masked_values_valid = random_mask_value(\n",
    "        tokenized_valid[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    print(\n",
    "        f\"random masking at epoch {epoch:3d}, ratio of masked values in train: \",\n",
    "        f\"{(masked_values_train == mask_value).sum() / (masked_values_train - pad_value).count_nonzero():.4f}\",\n",
    "    )\n",
    "\n",
    "    input_gene_ids_train, input_gene_ids_valid = (\n",
    "        tokenized_train[\"genes\"],\n",
    "        tokenized_valid[\"genes\"],\n",
    "    )\n",
    "    input_values_train, input_values_valid = masked_values_train, masked_values_valid\n",
    "    target_values_train, target_values_valid = (\n",
    "        tokenized_train[\"values\"],\n",
    "        tokenized_valid[\"values\"],\n",
    "    )\n",
    "\n",
    "    tensor_batch_labels_train = torch.from_numpy(train_batch_labels).long()\n",
    "    tensor_batch_labels_valid = torch.from_numpy(valid_batch_labels).long()\n",
    "\n",
    "    if sort_seq_batch:\n",
    "        train_sort_ids = np.argsort(train_batch_labels)\n",
    "        input_gene_ids_train = input_gene_ids_train[train_sort_ids]\n",
    "        input_values_train = input_values_train[train_sort_ids]\n",
    "        target_values_train = target_values_train[train_sort_ids]\n",
    "        tensor_batch_labels_train = tensor_batch_labels_train[train_sort_ids]\n",
    "\n",
    "        valid_sort_ids = np.argsort(valid_batch_labels)\n",
    "        input_gene_ids_valid = input_gene_ids_valid[valid_sort_ids]\n",
    "        input_values_valid = input_values_valid[valid_sort_ids]\n",
    "        target_values_valid = target_values_valid[valid_sort_ids]\n",
    "        tensor_batch_labels_valid = tensor_batch_labels_valid[valid_sort_ids]\n",
    "\n",
    "    train_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_train,\n",
    "        \"values\": input_values_train,\n",
    "        \"target_values\": target_values_train,\n",
    "        \"batch_labels\": tensor_batch_labels_train,\n",
    "    }\n",
    "    valid_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_valid,\n",
    "        \"values\": input_values_valid,\n",
    "        \"target_values\": target_values_valid,\n",
    "        \"batch_labels\": tensor_batch_labels_valid,\n",
    "    }\n",
    "\n",
    "    return train_data_pt, valid_data_pt\n",
    "\n",
    "\n",
    "# dataset\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data: Dict[str, torch.Tensor]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "\n",
    "# data_loader\n",
    "def prepare_dataloader(\n",
    "    data_pt: Dict[str, torch.Tensor],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    intra_domain_shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    dataset = SeqDataset(data_pt)\n",
    "\n",
    "    if per_seq_batch_sample:\n",
    "        # find the indices of samples in each seq batch\n",
    "        subsets = []\n",
    "        batch_labels_array = data_pt[\"batch_labels\"].numpy()\n",
    "        for batch_label in np.unique(batch_labels_array):\n",
    "            batch_indices = np.where(batch_labels_array == batch_label)[0].tolist()\n",
    "            subsets.append(batch_indices)\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_sampler=SubsetsBatchSampler(\n",
    "                subsets,\n",
    "                batch_size,\n",
    "                intra_subset_shuffle=intra_domain_shuffle,\n",
    "                inter_subset_shuffle=shuffle,\n",
    "                drop_last=drop_last,\n",
    "            ),\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return data_loader\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c23e3546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use domain specific batchnorm with affine=False\n",
      "scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([36574, 512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params decoder.fc.0.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params decoder.fc.2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params decoder.fc.2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params decoder.fc.4.weight with shape torch.Size([1, 512])\n",
      "scGPT - INFO - Loading params decoder.fc.4.bias with shape torch.Size([1])\n",
      "scGPT - INFO - Loading params mvc_decoder.gene2query.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params mvc_decoder.gene2query.bias with shape torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Create and finetune scGPT\n",
    "\n",
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    dropout=config.dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=config.GEPC,\n",
    "    do_dab=True,\n",
    "    use_batch_labels=True,\n",
    "    num_batch_labels=num_batch_types,\n",
    "    domain_spec_batchnorm=DSBN,\n",
    "    n_input_bins=n_input_bins,\n",
    "    ecs_threshold=config.ecs_thres,\n",
    "    explicit_zero_prob=explicit_zero_prob,\n",
    "    use_fast_transformer=True,\n",
    "    pre_norm=config.pre_norm,\n",
    ")\n",
    "if config.load_model is not None:\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        logger.info(f\"Loading all model params from {model_file}\")\n",
    "    except:\n",
    "        # only load params that are in the model and match the size\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = torch.load(model_file)\n",
    "        pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "        for k, v in pretrained_dict.items():\n",
    "            logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "model.to(device)\n",
    "# wandb.watch(model)\n",
    "\n",
    "\n",
    "# criterion = masked_mse_loss\n",
    "criterion = masked_ce_loss\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.transformer_encoder.layers[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "criterion_dab = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(), lr=config.lr,\n",
    "# )\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=config.lr, eps=1e-4 if config.amp else 1e-8\n",
    ")\n",
    "\n",
    "# optimizer = SophiaG(model.parameters(), lr=config.lr, betas=(0.965, 0.99), rho = 0.01, weight_decay=1e-1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=config.schedule_ratio)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa1b766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 324 × 11968\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster', 'batch', 'celltype', 'str_batch', 'batch_id'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'gene_name', 'id_in_vocab', 'n_counts'\n",
       "    uns: 'cluster_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'spatial', 'umap', 'log1p'\n",
       "    obsm: 'X_pca', 'X_umap', 'spatial', 'bin_edges'\n",
       "    varm: 'PCs'\n",
       "    layers: 'X_normed', 'X_log1p', 'X_binned'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51a31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf57207",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0844d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model: nn.Module, loader: DataLoader) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_mse, total_gepc = 0.0, 0.0, 0.0\n",
    "    total_error = 0.0\n",
    "    log_interval = config.log_interval\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(loader)\n",
    "    for batch, batch_data in enumerate(loader):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "        input_values = batch_data[\"values\"].to(device)\n",
    "        target_values = batch_data[\"target_values\"].to(device)\n",
    "        batch_labels = batch_data[\"batch_labels\"].to(device)\n",
    "        \n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "        with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "            output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=batch_labels if DSBN else None,\n",
    "                MVC=config.GEPC,\n",
    "                ECS=config.ecs_thres > 0,\n",
    "            )\n",
    "\n",
    "            masked_positions = input_values.eq(mask_value)  # the postions to predict\n",
    "            loss = loss_mse = criterion(\n",
    "                output_dict[\"mlm_output\"], target_values, masked_positions\n",
    "            )\n",
    "            \n",
    "            \n",
    "            # loss = loss_mse = torch.FloatTensor([0.0]).cuda()\n",
    "            \n",
    "            metrics_to_log = {\"train/mse\": loss_mse.item()}\n",
    "            \n",
    "            if explicit_zero_prob:\n",
    "                loss_zero_log_prob = criterion_neg_log_bernoulli(\n",
    "                    output_dict[\"mlm_zero_probs\"], target_values, masked_positions\n",
    "                )\n",
    "                loss = loss + loss_zero_log_prob\n",
    "                metrics_to_log.update({\"train/nzlp\": loss_zero_log_prob.item()})\n",
    "                \n",
    "            if config.GEPC:\n",
    "                loss_gepc = criterion(\n",
    "                    output_dict[\"mvc_output\"], target_values, masked_positions\n",
    "                )\n",
    "                loss = loss + loss_gepc\n",
    "                metrics_to_log.update({\"train/mvc\": loss_gepc.item()})\n",
    "                \n",
    "            if config.GEPC and explicit_zero_prob:\n",
    "                loss_gepc_zero_log_prob = criterion_neg_log_bernoulli(\n",
    "                    output_dict[\"mvc_zero_probs\"], target_values, masked_positions\n",
    "                )\n",
    "                loss = loss + loss_gepc_zero_log_prob\n",
    "                metrics_to_log.update(\n",
    "                    {\"train/mvc_nzlp\": loss_gepc_zero_log_prob.item()}\n",
    "                )\n",
    "                \n",
    "            if config.ecs_thres > 0:\n",
    "                loss_ecs = 10 * output_dict[\"loss_ecs\"]\n",
    "                loss = loss + loss_ecs\n",
    "                metrics_to_log.update({\"train/ecs\": loss_ecs.item()})\n",
    "                \n",
    "                \n",
    "#             loss_gepc = torch.FloatTensor([0.0])\n",
    "            \n",
    "            loss_dab = criterion_dab(output_dict[\"dab_output\"], batch_labels)\n",
    "#             loss = loss + config.dab_weight * loss_dab\n",
    "            loss_dab = torch.FloatTensor([0.0])\n",
    "            metrics_to_log.update({\"train/dab\": loss_dab.item()})\n",
    "\n",
    "        model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                logger.warning(\n",
    "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
    "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
    "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
    "                )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        wandb.log(metrics_to_log)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mre = masked_relative_error(\n",
    "                output_dict[\"mlm_output\"], target_values, masked_positions\n",
    "            )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item()\n",
    "        total_gepc += loss_gepc.item() if config.GEPC else 0.0\n",
    "        total_error += mre.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            cur_mse = total_mse / log_interval\n",
    "            cur_gepc = total_gepc / log_interval if config.GEPC else 0.0\n",
    "            cur_error = total_error / log_interval\n",
    "            # ppl = math.exp(cur_loss)\n",
    "            logger.info(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | mse {cur_mse:5.2f} | mre {cur_error:5.2f} |\"\n",
    "                + (f\"gepc {cur_gepc:5.2f} |\" if config.GEPC else \"\")\n",
    "            )\n",
    "            total_loss = 0\n",
    "            total_mse = 0\n",
    "            total_gepc = 0\n",
    "            total_error = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def define_wandb_metrcis():\n",
    "    wandb.define_metric(\"valid/mse\", summary=\"min\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"valid/mre\", summary=\"min\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"valid/dab\", summary=\"min\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"valid/sum_mse_dab\", summary=\"min\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"test/avg_bio\", summary=\"max\")\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the evaluation data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    total_dab = 0.0\n",
    "    total_num = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"values\"].to(device)\n",
    "            target_values = batch_data[\"target_values\"].to(device)\n",
    "            batch_labels = batch_data[\"batch_labels\"].to(device)\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=batch_labels if DSBN else None,\n",
    "                )\n",
    "                output_values = output_dict[\"mlm_output\"]\n",
    "\n",
    "                masked_positions = input_values.eq(mask_value)\n",
    "                loss = criterion(output_values, target_values, masked_positions)\n",
    "                loss_dab = criterion_dab(output_dict[\"dab_output\"], batch_labels)\n",
    "\n",
    "            total_loss += loss.item() * len(input_gene_ids)\n",
    "            total_error += masked_relative_error(\n",
    "                output_values, target_values, masked_positions\n",
    "            ).item() * len(input_gene_ids)\n",
    "            total_dab += loss_dab.item() * len(input_gene_ids)\n",
    "            total_num += len(input_gene_ids)\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"valid/mse\": total_loss / total_num,\n",
    "            \"valid/mre\": total_error / total_num,\n",
    "            \"valid/dab\": total_dab / total_num,\n",
    "            \"valid/sum_mse_dab\": (total_loss + config.dab_weight * total_dab)\n",
    "            / total_num,\n",
    "            \"epoch\": epoch,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return total_loss / total_num, total_error / total_num\n",
    "\n",
    "\n",
    "def eval_testdata(\n",
    "    model: nn.Module,\n",
    "    adata_t: AnnData,\n",
    "    include_types: List[str] = [\"cls\"],\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"evaluate the model on test dataset of adata_t\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # copy adata_t to avoid reuse previously computed results stored in adata_t\n",
    "    adata_t = adata_t.copy()\n",
    "\n",
    "    all_counts = (\n",
    "        adata_t.layers[input_layer_key].A\n",
    "        if issparse(adata_t.layers[input_layer_key])\n",
    "        else adata_t.layers[input_layer_key]\n",
    "    )\n",
    "\n",
    "    celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "    celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "    batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "    batch_ids = np.array(batch_ids)\n",
    "\n",
    "    # Evaluate cls cell embeddings\n",
    "    if \"cls\" in include_types:\n",
    "        logger.info(\"Evaluating cls cell embeddings\")\n",
    "        tokenized_all = tokenize_and_pad_batch(\n",
    "            all_counts,\n",
    "            gene_ids,\n",
    "            max_len=max_seq_len,\n",
    "            vocab=vocab,\n",
    "            pad_token=pad_token,\n",
    "            pad_value=pad_value,\n",
    "            append_cls=True,  # append <cls> token at the beginning\n",
    "            include_zero_gene=True,\n",
    "        )\n",
    "        all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "        src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=config.amp):\n",
    "            cell_embeddings = model.encode_batch(\n",
    "                all_gene_ids,\n",
    "                all_values.float(),\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_size=config.batch_size,\n",
    "                batch_labels=torch.from_numpy(batch_ids).long() if DSBN else None,\n",
    "                time_step=0,\n",
    "                return_np=True,\n",
    "            )\n",
    "        cell_embeddings = cell_embeddings / np.linalg.norm(\n",
    "            cell_embeddings, axis=1, keepdims=True\n",
    "        )\n",
    "\n",
    "        adata_t.obsm[\"X_scGPT\"] = cell_embeddings\n",
    "\n",
    "        results = {}\n",
    "        try:\n",
    "            results = eval_scib_metrics(adata_t)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            logger.error(e)\n",
    "\n",
    "        sc.pp.neighbors(adata_t, use_rep=\"X_scGPT\")\n",
    "        sc.tl.umap(adata_t, min_dist=0.3)\n",
    "        fig = sc.pl.umap(\n",
    "            adata_t,\n",
    "            color=[\"str_batch\"],\n",
    "            title=[f\"batch, avg_bio = {results.get('avg_bio', 0.0):.4f}\"],\n",
    "            frameon=False,\n",
    "            return_fig=True,\n",
    "            show=False,\n",
    "        )\n",
    "\n",
    "        results[\"batch_umap\"] = fig\n",
    "\n",
    "        sc.pp.neighbors(adata_t, use_rep=\"X_scGPT\")\n",
    "        sc.tl.umap(adata_t, min_dist=0.3)\n",
    "        fig = sc.pl.umap(\n",
    "            adata_t,\n",
    "            color=[\"celltype\"],\n",
    "            title=[\n",
    "                f\"celltype, avg_bio = {results.get('avg_bio', 0.0):.4f}\",\n",
    "            ],\n",
    "            frameon=False,\n",
    "            return_fig=True,\n",
    "            show=False,\n",
    "        )\n",
    "\n",
    "        results[\"celltype_umap\"] = fig\n",
    "\n",
    "    if len(include_types) == 1:\n",
    "        return results\n",
    "    \n",
    "    \n",
    "def return_testdata(\n",
    "    model: nn.Module,\n",
    "    adata_t: AnnData,\n",
    "    include_types: List[str] = [\"cls\"],\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"evaluate the model on test dataset of adata_t\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # copy adata_t to avoid reuse previously computed results stored in adata_t\n",
    "    adata_t = adata_t.copy()\n",
    "\n",
    "    all_counts = (\n",
    "        adata_t.layers[input_layer_key].A\n",
    "        if issparse(adata_t.layers[input_layer_key])\n",
    "        else adata_t.layers[input_layer_key]\n",
    "    )\n",
    "\n",
    "    celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "    celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "    batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "    batch_ids = np.array(batch_ids)\n",
    "\n",
    "    # Evaluate cls cell embeddings\n",
    "    if \"cls\" in include_types:\n",
    "        logger.info(\"Evaluating cls cell embeddings\")\n",
    "        tokenized_all = tokenize_and_pad_batch(\n",
    "            all_counts,\n",
    "            gene_ids,\n",
    "            max_len=max_seq_len,\n",
    "            vocab=vocab,\n",
    "            pad_token=pad_token,\n",
    "            pad_value=pad_value,\n",
    "            append_cls=True,  # append <cls> token at the beginning\n",
    "            include_zero_gene=True,\n",
    "        )\n",
    "        all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "        src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=config.amp):\n",
    "            cell_embeddings = model.encode_batch(\n",
    "                all_gene_ids,\n",
    "                all_values.float(),\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_size=config.batch_size,\n",
    "                batch_labels=torch.from_numpy(batch_ids).long() if DSBN else None,\n",
    "                time_step=0,\n",
    "                return_np=True,\n",
    "            )\n",
    "        cell_embeddings = cell_embeddings / np.linalg.norm(\n",
    "            cell_embeddings, axis=1, keepdims=True\n",
    "        )\n",
    "        \n",
    "    return cell_embeddings\n",
    "\n",
    "\n",
    "def simulation_data(\n",
    "    model: nn.Module,\n",
    "    adata_t: AnnData,\n",
    "    include_types: List[str] = [\"cls\"],\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"evaluate the model on test dataset of adata_t\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    mlm_out = []\n",
    "    \n",
    "    # copy adata_t to avoid reuse previously computed results stored in adata_t\n",
    "    adata_t = adata_t.copy()\n",
    "\n",
    "    for i in adata_t.obs_names:\n",
    "        adata_new = adata_t[i,:]\n",
    "\n",
    "        all_counts = (\n",
    "            adata_new.layers[input_layer_key].A\n",
    "            if issparse(adata_new.layers[input_layer_key])\n",
    "            else adata_new.layers[input_layer_key]\n",
    "        )\n",
    "\n",
    "        celltypes_labels = adata_new.obs[\"celltype\"].tolist()\n",
    "        celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "        batch_ids = adata_new.obs[\"batch_id\"].tolist()\n",
    "        batch_ids = np.array(batch_ids)\n",
    "\n",
    "        # Evaluate cls cell embeddings\n",
    "        if \"cls\" in include_types:\n",
    "            # logger.info(\"Evaluating cls cell embeddings\")\n",
    "            tokenized_all = tokenize_and_pad_batch(\n",
    "                all_counts,\n",
    "                gene_ids,\n",
    "                max_len=max_seq_len,\n",
    "                vocab=vocab,\n",
    "                pad_token=pad_token,\n",
    "                pad_value=pad_value,\n",
    "                append_cls=True,  # append <cls> token at the beginning\n",
    "                include_zero_gene=True,\n",
    "            )\n",
    "            all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "            src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])\n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    all_gene_ids.cuda(),\n",
    "                    all_values.float().cuda(),\n",
    "                    src_key_padding_mask=src_key_padding_mask.cuda(),\n",
    "                    batch_labels=torch.from_numpy(batch_ids).long().cuda()  if DSBN else None,\n",
    "                    MVC=config.GEPC,\n",
    "                    ECS=config.ecs_thres > 0,\n",
    "                )\n",
    "                \n",
    "                mlm_out.append(output_dict[\"mlm_output\"].cpu().detach().numpy()[0] \n",
    "                               * ((output_dict[\"mlm_zero_probs\"]>0.5)*1).cpu().detach().numpy()[0])\n",
    "    \n",
    "    return mlm_out\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84310c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7fdef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict = simulation_data(best_model,\n",
    "    adata_t=adata_sorted if per_seq_batch_sample else adata,\n",
    "    include_types=[\"cls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ba57dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3.38867188, 3.40625   , 3.4609375 , ..., 3.48828125, 3.40234375,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.39648438, 3.453125  , ..., 3.49023438, 3.4140625 ,\n",
       "        3.3359375 ]),\n",
       " array([3.39257812, 3.39257812, 3.44140625, ..., 3.50195312, 3.34960938,\n",
       "        3.33007812]),\n",
       " array([3.39453125, 3.41210938, 3.4609375 , ..., 3.41210938, 3.41015625,\n",
       "        3.34570312]),\n",
       " array([3.38867188, 3.4140625 , 3.46484375, ..., 3.484375  , 3.43359375,\n",
       "        3.34570312]),\n",
       " array([3.390625  , 3.40234375, 3.37304688, ..., 3.48828125, 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40429688, 3.45703125, ..., 3.48828125, 3.36914062,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40234375, 3.4609375 , ..., 3.390625  , 3.37109375,\n",
       "        3.34179688]),\n",
       " array([3.390625  , 3.4140625 , 3.46484375, ..., 3.48632812, 3.38867188,\n",
       "        3.34765625]),\n",
       " array([3.39453125, 3.41015625, 3.46484375, ..., 3.48632812, 3.390625  ,\n",
       "        3.34765625]),\n",
       " array([3.38476562, 3.390625  , 3.44726562, ..., 3.48632812, 3.35351562,\n",
       "        3.33203125]),\n",
       " array([3.390625  , 3.40234375, 3.3984375 , ..., 3.4921875 , 3.36132812,\n",
       "        3.41992188]),\n",
       " array([3.38671875, 3.3984375 , 3.45507812, ..., 3.45898438, 3.36132812,\n",
       "        3.33398438]),\n",
       " array([3.38867188, 3.40039062, 3.45703125, ..., 3.484375  , 3.36914062,\n",
       "        3.33984375]),\n",
       " array([3.39257812, 3.39648438, 3.44921875, ..., 3.49023438, 3.35742188,\n",
       "        3.33789062]),\n",
       " array([3.40820312, 3.41796875, 3.46289062, ..., 3.47460938, 3.421875  ,\n",
       "        3.34960938]),\n",
       " array([3.38085938, 3.39648438, 3.44921875, ..., 3.48632812, 3.36328125,\n",
       "        3.33203125]),\n",
       " array([3.39453125, 3.390625  , 3.44335938, ..., 3.44921875, 3.34960938,\n",
       "        3.33203125]),\n",
       " array([3.38085938, 3.40625   , 3.45703125, ..., 3.484375  , 3.37695312,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40234375, 3.45507812, ..., 3.48632812, 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.39453125, 3.45703125, ..., 3.48632812, 3.359375  ,\n",
       "        3.33398438]),\n",
       " array([3.38671875, 3.39257812, 3.45703125, ..., 3.48828125, 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.40625   , 3.45898438, ..., 3.48632812, 3.37695312,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40429688, 3.45703125, ..., 3.43554688, 3.45703125,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.39648438, 3.45117188, ..., 3.48828125, 3.35742188,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.39453125, 3.44726562, ..., 3.48828125, 3.35351562,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.41601562, 3.46679688, ..., 3.484375  , 3.44335938,\n",
       "        3.34765625]),\n",
       " array([3.38671875, 3.3984375 , 3.453125  , ..., 3.48632812, 3.44921875,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.41015625, 3.45898438, ..., 3.48632812, 3.3671875 ,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.40429688, 3.45703125, ..., 3.45507812, 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.3984375 , 3.45507812, ..., 3.48828125, 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40625   , 3.45898438, ..., 3.48046875, 3.41601562,\n",
       "        3.34570312]),\n",
       " array([3.390625  , 3.40429688, 3.45898438, ..., 3.48828125, 3.36914062,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.40039062, 3.453125  , ..., 3.48828125, 3.36328125,\n",
       "        3.3359375 ]),\n",
       " array([3.39453125, 3.390625  , 3.44335938, ..., 3.48632812, 3.34960938,\n",
       "        3.33007812]),\n",
       " array([3.38867188, 3.390625  , 3.44140625, ..., 3.48828125, 3.3515625 ,\n",
       "        3.328125  ]),\n",
       " array([3.38476562, 3.4453125 , 3.46289062, ..., 3.48828125, 3.37695312,\n",
       "        3.33984375]),\n",
       " array([3.3828125 , 3.39648438, 3.45117188, ..., 3.48632812, 3.36328125,\n",
       "        3.33398438]),\n",
       " array([3.38867188, 3.39453125, 3.453125  , ..., 3.484375  , 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.40429688, 3.453125  , ..., 3.48828125, 3.36914062,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.3984375 , 3.45703125, ..., 3.44335938, 3.36132812,\n",
       "        3.33398438]),\n",
       " array([3.40039062, 3.4140625 , 3.4609375 , ..., 3.47460938, 3.41601562,\n",
       "        3.34765625]),\n",
       " array([3.38867188, 3.39453125, 3.45117188, ..., 3.4921875 , 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38671875, 3.40429688, 3.45898438, ..., 3.48632812, 3.40039062,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.3984375 , 3.45703125, ..., 3.38085938, 3.35742188,\n",
       "        3.3359375 ]),\n",
       " array([3.41601562, 3.42382812, 3.4609375 , ..., 3.47460938, 3.4296875 ,\n",
       "        3.3515625 ]),\n",
       " array([3.38867188, 3.3984375 , 3.44921875, ..., 3.48632812, 3.35546875,\n",
       "        3.33203125]),\n",
       " array([3.38476562, 3.40234375, 3.453125  , ..., 3.484375  , 3.36914062,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40625   , 3.43359375, ..., 3.48632812, 3.38085938,\n",
       "        3.33984375]),\n",
       " array([3.39257812, 3.40429688, 3.4609375 , ..., 3.4375    , 3.41015625,\n",
       "        3.34179688]),\n",
       " array([3.39257812, 3.40234375, 3.45898438, ..., 3.49023438, 3.36523438,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.41015625, 3.4609375 , ..., 3.47460938, 3.45703125,\n",
       "        3.34765625]),\n",
       " array([3.38867188, 3.3984375 , 3.45507812, ..., 3.48828125, 3.36328125,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.39648438, 3.46484375, ..., 3.40820312, 3.35351562,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.40820312, 3.4609375 , ..., 3.40625   , 3.37304688,\n",
       "        3.34375   ]),\n",
       " array([3.38671875, 3.40429688, 3.45703125, ..., 3.484375  , 3.375     ,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.40820312, 3.4609375 , ..., 3.41210938, 3.37695312,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40820312, 3.4609375 , ..., 3.48632812, 3.375     ,\n",
       "        3.34179688]),\n",
       " array([3.38671875, 3.39257812, 3.4453125 , ..., 3.48828125, 3.3515625 ,\n",
       "        3.33007812]),\n",
       " array([3.38671875, 3.40234375, 3.45703125, ..., 3.49023438, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.38085938, 3.40039062, 3.453125  , ..., 3.48828125, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.3828125 , 3.40429688, 3.46679688, ..., 3.47070312, 3.37109375,\n",
       "        3.3359375 ]),\n",
       " array([3.39257812, 3.40039062, 3.4609375 , ..., 3.38867188, 3.3671875 ,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.40820312, 3.46289062, ..., 3.4921875 , 3.375     ,\n",
       "        3.34375   ]),\n",
       " array([3.3828125 , 3.40429688, 3.45507812, ..., 3.48632812, 3.37695312,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.40625   , 3.46289062, ..., 3.48632812, 3.38085938,\n",
       "        3.34570312]),\n",
       " array([3.390625  , 3.40429688, 3.45898438, ..., 3.40429688, 3.36523438,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40429688, 3.45703125, ..., 3.48632812, 3.37304688,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.3984375 , 3.45117188, ..., 3.4140625 , 3.36132812,\n",
       "        3.33398438]),\n",
       " array([3.38476562, 3.41210938, 3.46289062, ..., 3.46289062, 3.38671875,\n",
       "        3.34179688]),\n",
       " array([3.38476562, 3.40429688, 3.45703125, ..., 3.49023438, 3.38085938,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.40429688, 3.46289062, ..., 3.4375    , 3.37304688,\n",
       "        3.34179688]),\n",
       " array([3.39453125, 3.40039062, 3.45117188, ..., 3.4921875 , 3.35742188,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.40039062, 3.45507812, ..., 3.46484375, 3.42578125,\n",
       "        3.33398438]),\n",
       " array([3.390625  , 3.40820312, 3.46484375, ..., 3.49023438, 3.37304688,\n",
       "        3.33984375]),\n",
       " array([3.38476562, 3.40234375, 3.45898438, ..., 3.48632812, 3.41015625,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40625   , 3.45703125, ..., 3.484375  , 3.40625   ,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.39648438, 3.453125  , ..., 3.484375  , 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.39648438, 3.36328125, ..., 3.48828125, 3.36132812,\n",
       "        3.33398438]),\n",
       " array([3.38671875, 3.40429688, 3.45507812, ..., 3.47851562, 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40234375, 3.45703125, ..., 3.48632812, 3.37695312,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.39257812, 3.39648438, ..., 3.5       , 3.35546875,\n",
       "        3.33203125]),\n",
       " array([3.40625   , 3.4140625 , 3.46679688, ..., 3.43554688, 3.41210938,\n",
       "        3.35351562]),\n",
       " array([3.39453125, 3.41210938, 3.453125  , ..., 3.4765625 , 3.40820312,\n",
       "        3.34765625]),\n",
       " array([3.3984375 , 3.40820312, 3.4609375 , ..., 3.4765625 , 3.40234375,\n",
       "        3.3984375 ]),\n",
       " array([3.390625  , 3.40820312, 3.46289062, ..., 3.4921875 , 3.38085938,\n",
       "        3.34570312]),\n",
       " array([3.38671875, 3.41210938, 3.46289062, ..., 3.484375  , 3.38476562,\n",
       "        3.34375   ]),\n",
       " array([3.38867188, 3.3984375 , 3.45507812, ..., 3.41210938, 3.35742188,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.41210938, 3.4609375 , ..., 3.38671875, 3.38476562,\n",
       "        3.34570312]),\n",
       " array([3.38867188, 3.40429688, 3.45898438, ..., 3.48632812, 3.36914062,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.39453125, 3.44921875, ..., 3.49023438, 3.35546875,\n",
       "        3.33398438]),\n",
       " array([3.3828125 , 3.39257812, 3.453125  , ..., 3.421875  , 3.36132812,\n",
       "        3.33203125]),\n",
       " array([3.38867188, 3.45507812, 3.4609375 , ..., 3.484375  , 3.37695312,\n",
       "        3.34179688]),\n",
       " array([3.390625  , 3.39453125, 3.453125  , ..., 3.48828125, 3.39257812,\n",
       "        3.3359375 ]),\n",
       " array([3.39257812, 3.38671875, 3.45703125, ..., 3.49804688, 3.35742188,\n",
       "        3.33789062]),\n",
       " array([3.39257812, 3.4140625 , 3.46484375, ..., 3.48242188, 3.39453125,\n",
       "        3.34765625]),\n",
       " array([3.40625   , 3.4140625 , 3.46679688, ..., 3.47851562, 3.41210938,\n",
       "        3.34960938]),\n",
       " array([3.390625  , 3.41015625, 3.45898438, ..., 3.49023438, 3.37695312,\n",
       "        3.34179688]),\n",
       " array([3.38671875, 3.39453125, 3.44726562, ..., 3.48828125, 3.35351562,\n",
       "        3.33203125]),\n",
       " array([3.38867188, 3.40234375, 3.421875  , ..., 3.37890625, 3.37304688,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.3984375 , 3.45507812, ..., 3.50195312, 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.40234375, 3.4609375 , ..., 3.48828125, 3.3671875 ,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.41210938, 3.46679688, ..., 3.49023438, 3.38085938,\n",
       "        3.34179688]),\n",
       " array([3.38671875, 3.40429688, 3.45898438, ..., 3.45703125, 3.4296875 ,\n",
       "        3.34375   ]),\n",
       " array([3.38476562, 3.3984375 , 3.44921875, ..., 3.48632812, 3.36132812,\n",
       "        3.33398438]),\n",
       " array([3.38476562, 3.3984375 , 3.45507812, ..., 3.48828125, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.39453125, 3.43359375, 3.46484375, ..., 3.421875  , 3.40039062,\n",
       "        3.34765625]),\n",
       " array([3.38671875, 3.40234375, 3.45507812, ..., 3.484375  , 3.375     ,\n",
       "        3.33789062]),\n",
       " array([3.38476562, 3.40429688, 3.45898438, ..., 3.48828125, 3.37109375,\n",
       "        3.33789062]),\n",
       " array([3.39257812, 3.38867188, 3.4453125 , ..., 3.4921875 , 3.34960938,\n",
       "        3.33203125]),\n",
       " array([3.40429688, 3.4140625 , 3.46484375, ..., 3.4765625 , 3.41210938,\n",
       "        3.3515625 ]),\n",
       " array([3.38671875, 3.40820312, 3.45898438, ..., 3.484375  , 3.3828125 ,\n",
       "        3.34179688]),\n",
       " array([3.39257812, 3.40820312, 3.46289062, ..., 3.49023438, 3.37109375,\n",
       "        3.34179688]),\n",
       " array([3.40039062, 3.41796875, 3.46289062, ..., 3.43164062, 3.41796875,\n",
       "        3.35351562]),\n",
       " array([3.390625  , 3.40234375, 3.45703125, ..., 3.4375    , 3.44140625,\n",
       "        3.33789062]),\n",
       " array([3.39453125, 3.3984375 , 3.44921875, ..., 3.49023438, 3.40625   ,\n",
       "        3.3359375 ]),\n",
       " array([3.39648438, 3.41015625, 3.46679688, ..., 3.48632812, 3.38867188,\n",
       "        3.34765625]),\n",
       " array([3.39257812, 3.3984375 , 3.453125  , ..., 3.48632812, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.3828125 , 3.3984375 , 3.45117188, ..., 3.48242188, 3.36328125,\n",
       "        3.34960938]),\n",
       " array([3.38476562, 3.390625  , 3.44335938, ..., 3.48632812, 3.35351562,\n",
       "        3.328125  ]),\n",
       " array([3.38867188, 3.39453125, 3.45117188, ..., 3.48828125, 3.359375  ,\n",
       "        3.3828125 ]),\n",
       " array([3.38867188, 3.39257812, 3.44335938, ..., 3.48828125, 3.3515625 ,\n",
       "        3.33398438]),\n",
       " array([3.41015625, 3.42382812, 3.46289062, ..., 3.4765625 , 3.42578125,\n",
       "        3.3515625 ]),\n",
       " array([3.39257812, 3.39453125, 3.44726562, ..., 3.43554688, 3.34960938,\n",
       "        3.33203125]),\n",
       " array([3.38867188, 3.40625   , 3.4609375 , ..., 3.48632812, 3.38085938,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.3984375 , 3.45898438, ..., 3.49023438, 3.36914062,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.39257812, 3.44335938, ..., 3.48828125, 3.35546875,\n",
       "        3.33203125]),\n",
       " array([3.390625  , 3.40820312, 3.45898438, ..., 3.48632812, 3.37890625,\n",
       "        3.34375   ]),\n",
       " array([3.390625  , 3.40429688, 3.46289062, ..., 3.49023438, 3.36914062,\n",
       "        3.34179688]),\n",
       " array([3.3828125 , 3.3984375 , 3.45507812, ..., 3.48632812, 3.3984375 ,\n",
       "        3.33398438]),\n",
       " array([3.390625  , 3.40820312, 3.4609375 , ..., 3.48632812, 3.38085938,\n",
       "        3.34765625]),\n",
       " array([3.38476562, 3.390625  , 3.4453125 , ..., 3.46875   , 3.35351562,\n",
       "        3.33398438]),\n",
       " array([3.38867188, 3.40234375, 3.45703125, ..., 3.48632812, 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40039062, 3.45117188, ..., 3.48828125, 3.36328125,\n",
       "        3.33789062]),\n",
       " array([3.40429688, 3.41601562, 3.47070312, ..., 3.47460938, 3.43359375,\n",
       "        3.34960938]),\n",
       " array([3.39257812, 3.40234375, 3.44140625, ..., 3.4921875 , 3.3671875 ,\n",
       "        3.34375   ]),\n",
       " array([3.38671875, 3.40820312, 3.42773438, ..., 3.48632812, 3.375     ,\n",
       "        3.34375   ]),\n",
       " array([3.38867188, 3.390625  , 3.44335938, ..., 3.38867188, 3.40625   ,\n",
       "        3.33007812]),\n",
       " array([3.38476562, 3.390625  , 3.45507812, ..., 3.484375  , 3.35351562,\n",
       "        3.33007812]),\n",
       " array([3.38867188, 3.40429688, 3.45898438, ..., 3.484375  , 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.39257812, 3.41015625, 3.4609375 , ..., 3.48632812, 3.38476562,\n",
       "        3.34570312]),\n",
       " array([3.38671875, 3.39648438, 3.453125  , ..., 3.45703125, 3.36328125,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40039062, 3.45507812, ..., 3.48828125, 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.40820312, 3.45898438, ..., 3.48632812, 3.37695312,\n",
       "        3.34570312]),\n",
       " array([3.38671875, 3.3984375 , 3.45703125, ..., 3.48828125, 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38671875, 3.41015625, 3.46289062, ..., 3.484375  , 3.38085938,\n",
       "        3.34375   ]),\n",
       " array([3.40625   , 3.41992188, 3.46875   , ..., 3.38671875, 3.4140625 ,\n",
       "        3.35351562]),\n",
       " array([3.38867188, 3.40820312, 3.45898438, ..., 3.48632812, 3.37695312,\n",
       "        3.34179688]),\n",
       " array([3.41015625, 3.41992188, 3.45898438, ..., 3.421875  , 3.42773438,\n",
       "        3.3515625 ]),\n",
       " array([3.40039062, 3.41601562, 3.45898438, ..., 3.47460938, 3.41210938,\n",
       "        3.3515625 ]),\n",
       " array([3.39453125, 3.41210938, 3.46484375, ..., 3.44726562, 3.40234375,\n",
       "        3.34960938]),\n",
       " array([3.38867188, 3.41015625, 3.3671875 , ..., 3.48828125, 3.41796875,\n",
       "        3.34375   ]),\n",
       " array([3.39257812, 3.40625   , 3.46289062, ..., 3.48828125, 3.37109375,\n",
       "        3.34179688]),\n",
       " array([3.38671875, 3.40625   , 3.4609375 , ..., 3.484375  , 3.375     ,\n",
       "        3.33984375]),\n",
       " array([3.38085938, 3.40234375, 3.45507812, ..., 3.41796875, 3.375     ,\n",
       "        3.33203125]),\n",
       " array([3.38867188, 3.40625   , 3.46289062, ..., 3.48828125, 3.37695312,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.40429688, 3.45703125, ..., 3.47851562, 3.36914062,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.40429688, 3.45898438, ..., 3.41796875, 3.3671875 ,\n",
       "        3.34179688]),\n",
       " array([3.39453125, 3.390625  , 3.43554688, ..., 3.49804688, 3.3515625 ,\n",
       "        3.33789062]),\n",
       " array([3.39648438, 3.41015625, 3.46679688, ..., 3.48242188, 3.39648438,\n",
       "        3.34765625]),\n",
       " array([3.38671875, 3.39648438, 3.36523438, ..., 3.49023438, 3.359375  ,\n",
       "        3.33398438]),\n",
       " array([3.40429688, 3.41796875, 3.46289062, ..., 3.47265625, 3.41992188,\n",
       "        3.34960938]),\n",
       " array([3.38476562, 3.40429688, 3.45703125, ..., 3.484375  , 3.375     ,\n",
       "        3.34179688]),\n",
       " array([3.39257812, 3.41015625, 3.46289062, ..., 3.48828125, 3.37304688,\n",
       "        3.34179688]),\n",
       " array([3.38476562, 3.39453125, 3.4453125 , ..., 3.48828125, 3.35546875,\n",
       "        3.33007812]),\n",
       " array([3.390625  , 3.40625   , 3.4609375 , ..., 3.49023438, 3.3671875 ,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.40820312, 3.4609375 , ..., 3.48828125, 3.37890625,\n",
       "        3.34570312]),\n",
       " array([3.390625  , 3.40234375, 3.45507812, ..., 3.48828125, 3.36328125,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.41015625, 3.46289062, ..., 3.48046875, 3.390625  ,\n",
       "        3.34570312]),\n",
       " array([3.38867188, 3.39257812, 3.44335938, ..., 3.49023438, 3.34960938,\n",
       "        3.33398438]),\n",
       " array([3.390625  , 3.39257812, 3.44335938, ..., 3.48828125, 3.40820312,\n",
       "        3.33398438]),\n",
       " array([3.390625  , 3.40234375, 3.45507812, ..., 3.48828125, 3.39257812,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.38671875, 3.4609375 , ..., 3.49023438, 3.37109375,\n",
       "        3.34179688]),\n",
       " array([3.390625  , 3.40429688, 3.37304688, ..., 3.42382812, 3.36914062,\n",
       "        3.34179688]),\n",
       " array([3.38671875, 3.40234375, 3.45703125, ..., 3.48632812, 3.37109375,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.41210938, 3.46289062, ..., 3.484375  , 3.390625  ,\n",
       "        3.34375   ]),\n",
       " array([3.38867188, 3.40234375, 3.44140625, ..., 3.484375  , 3.37304688,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.40429688, 3.4609375 , ..., 3.4921875 , 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.41015625, 3.46289062, ..., 3.48632812, 3.38085938,\n",
       "        3.34375   ]),\n",
       " array([3.390625  , 3.39648438, 3.45117188, ..., 3.48828125, 3.35546875,\n",
       "        3.3359375 ]),\n",
       " array([3.38671875, 3.390625  , 3.43945312, ..., 3.484375  , 3.34960938,\n",
       "        3.328125  ]),\n",
       " array([3.390625  , 3.3984375 , 3.453125  , ..., 3.49023438, 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.41210938, 3.42382812, 3.46289062, ..., 3.4765625 , 3.42773438,\n",
       "        3.3515625 ]),\n",
       " array([3.39453125, 3.39257812, 3.4375    , ..., 3.390625  , 3.34765625,\n",
       "        3.33007812]),\n",
       " array([3.390625  , 3.40039062, 3.45117188, ..., 3.46484375, 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.40234375, 3.45898438, ..., 3.484375  , 3.36914062,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40234375, 3.4609375 , ..., 3.48632812, 3.37304688,\n",
       "        3.33984375]),\n",
       " array([3.38476562, 3.39257812, 3.35351562, ..., 3.484375  , 3.35742188,\n",
       "        3.33203125]),\n",
       " array([3.39257812, 3.41015625, 3.46289062, ..., 3.48828125, 3.38671875,\n",
       "        3.34960938]),\n",
       " array([3.390625  , 3.39453125, 3.45117188, ..., 3.41992188, 3.35742188,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.39648438, 3.45117188, ..., 3.48632812, 3.36328125,\n",
       "        3.33398438]),\n",
       " array([3.38867188, 3.40820312, 3.46289062, ..., 3.484375  , 3.38671875,\n",
       "        3.34375   ]),\n",
       " array([3.38671875, 3.40039062, 3.45117188, ..., 3.48828125, 3.36523438,\n",
       "        3.33398438]),\n",
       " array([3.38671875, 3.39648438, 3.45507812, ..., 3.48632812, 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.41015625, 3.4609375 , ..., 3.46679688, 3.39648438,\n",
       "        3.34765625]),\n",
       " array([3.3828125 , 3.40429688, 3.45703125, ..., 3.48242188, 3.40429688,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.390625  , 3.44921875, ..., 3.49023438, 3.35351562,\n",
       "        3.33398438]),\n",
       " array([3.4140625 , 3.42382812, 3.46289062, ..., 3.41601562, 3.4296875 ,\n",
       "        3.35546875]),\n",
       " array([3.38867188, 3.3984375 , 3.453125  , ..., 3.48632812, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.39257812, 3.3984375 , 3.45703125, ..., 3.46289062, 3.359375  ,\n",
       "        3.33789062]),\n",
       " array([3.39453125, 3.3984375 , 3.45703125, ..., 3.40429688, 3.35546875,\n",
       "        3.3359375 ]),\n",
       " array([3.3828125 , 3.3984375 , 3.45117188, ..., 3.48632812, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.41210938, 3.41992188, 3.4609375 , ..., 3.47460938, 3.42773438,\n",
       "        3.34960938]),\n",
       " array([3.390625  , 3.41015625, 3.45898438, ..., 3.48632812, 3.390625  ,\n",
       "        3.34960938]),\n",
       " array([3.38476562, 3.3984375 , 3.44726562, ..., 3.48632812, 3.36523438,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.39453125, 3.453125  , ..., 3.49023438, 3.359375  ,\n",
       "        3.33203125]),\n",
       " array([3.38476562, 3.40625   , 3.45703125, ..., 3.49414062, 3.37109375,\n",
       "        3.33398438]),\n",
       " array([3.3828125 , 3.40039062, 3.45507812, ..., 3.484375  , 3.41796875,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.40429688, 3.46289062, ..., 3.4921875 , 3.36914062,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.40039062, 3.45703125, ..., 3.49023438, 3.36328125,\n",
       "        3.33984375]),\n",
       " array([3.38476562, 3.390625  , 3.44335938, ..., 3.38476562, 3.34960938,\n",
       "        3.33007812]),\n",
       " array([3.421875  , 3.42773438, 3.4609375 , ..., 3.46289062, 3.4296875 ,\n",
       "        3.35742188]),\n",
       " array([3.3984375 , 3.40820312, 3.46289062, ..., 3.48242188, 3.3984375 ,\n",
       "        3.34960938]),\n",
       " array([3.38867188, 3.40429688, 3.45703125, ..., 3.484375  , 3.375     ,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.40234375, 3.45507812, ..., 3.48828125, 3.3671875 ,\n",
       "        3.33789062]),\n",
       " array([3.41601562, 3.42382812, 3.46484375, ..., 3.47851562, 3.4296875 ,\n",
       "        3.35351562]),\n",
       " array([3.37890625, 3.39648438, 3.45117188, ..., 3.484375  , 3.36523438,\n",
       "        3.33007812]),\n",
       " array([3.39257812, 3.41015625, 3.4609375 , ..., 3.47851562, 3.40234375,\n",
       "        3.34765625]),\n",
       " array([3.39257812, 3.40234375, 3.45507812, ..., 3.39257812, 3.3671875 ,\n",
       "        3.46679688]),\n",
       " array([3.41796875, 3.42382812, 3.45898438, ..., 3.43945312, 3.4296875 ,\n",
       "        3.35546875]),\n",
       " array([3.3828125 , 3.40234375, 3.453125  , ..., 3.50195312, 3.37109375,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40039062, 3.45898438, ..., 3.47460938, 3.43554688,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.40820312, 3.4609375 , ..., 3.484375  , 3.3828125 ,\n",
       "        3.34375   ]),\n",
       " array([3.38476562, 3.40625   , 3.45898438, ..., 3.48632812, 3.37890625,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.3984375 , 3.44726562, ..., 3.48632812, 3.35546875,\n",
       "        3.33789062]),\n",
       " array([3.39257812, 3.40234375, 3.45507812, ..., 3.48632812, 3.3671875 ,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.40234375, 3.45898438, ..., 3.484375  , 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40429688, 3.45703125, ..., 3.484375  , 3.37109375,\n",
       "        3.3359375 ]),\n",
       " array([3.3828125 , 3.40039062, 3.45507812, ..., 3.48242188, 3.36914062,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40625   , 3.4609375 , ..., 3.49023438, 3.37109375,\n",
       "        3.34179688]),\n",
       " array([3.38867188, 3.43945312, 3.4609375 , ..., 3.484375  , 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.41015625, 3.38476562, ..., 3.48828125, 3.3828125 ,\n",
       "        3.34570312]),\n",
       " array([3.39453125, 3.41210938, 3.46289062, ..., 3.4296875 , 3.38085938,\n",
       "        3.34570312]),\n",
       " array([3.40429688, 3.41601562, 3.46679688, ..., 3.47851562, 3.4140625 ,\n",
       "        3.3515625 ]),\n",
       " array([3.39257812, 3.40625   , 3.46484375, ..., 3.42382812, 3.375     ,\n",
       "        3.34375   ]),\n",
       " array([3.38671875, 3.40625   , 3.43359375, ..., 3.484375  , 3.36914062,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40039062, 3.45507812, ..., 3.49023438, 3.36523438,\n",
       "        3.33984375]),\n",
       " array([3.390625  , 3.41015625, 3.46484375, ..., 3.49023438, 3.37890625,\n",
       "        3.34570312]),\n",
       " array([3.38867188, 3.40429688, 3.4609375 , ..., 3.44140625, 3.41796875,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40039062, 3.45703125, ..., 3.48632812, 3.3671875 ,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.40234375, 3.45703125, ..., 3.484375  , 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40234375, 3.45898438, ..., 3.48632812, 3.37304688,\n",
       "        3.31835938]),\n",
       " array([3.41992188, 3.42578125, 3.46289062, ..., 3.47070312, 3.43164062,\n",
       "        3.35742188]),\n",
       " array([3.38867188, 3.40625   , 3.4609375 , ..., 3.48632812, 3.38476562,\n",
       "        3.34375   ]),\n",
       " array([3.38867188, 3.40625   , 3.38671875, ..., 3.40820312, 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40625   , 3.45703125, ..., 3.4765625 , 3.38085938,\n",
       "        3.34179688]),\n",
       " array([3.390625  , 3.41015625, 3.46289062, ..., 3.48242188, 3.38867188,\n",
       "        3.34375   ]),\n",
       " array([3.38867188, 3.40039062, 3.45898438, ..., 3.50390625, 3.36328125,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.41210938, 3.4375    , ..., 3.48242188, 3.390625  ,\n",
       "        3.34375   ]),\n",
       " array([3.390625  , 3.38867188, 3.44335938, ..., 3.46875   , 3.34765625,\n",
       "        3.328125  ]),\n",
       " array([3.38867188, 3.40625   , 3.45898438, ..., 3.48632812, 3.375     ,\n",
       "        3.34179688]),\n",
       " array([3.39257812, 3.40820312, 3.4609375 , ..., 3.38671875, 3.39453125,\n",
       "        3.34570312]),\n",
       " array([3.38671875, 3.38476562, 3.4609375 , ..., 3.48632812, 3.37109375,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.40820312, 3.46289062, ..., 3.48828125, 3.38476562,\n",
       "        3.34570312]),\n",
       " array([3.390625  , 3.40820312, 3.46289062, ..., 3.49023438, 3.37304688,\n",
       "        3.34375   ]),\n",
       " array([3.38867188, 3.40234375, 3.36328125, ..., 3.484375  , 3.3671875 ,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.41015625, 3.4609375 , ..., 3.4765625 , 3.38867188,\n",
       "        3.34570312]),\n",
       " array([3.38867188, 3.41601562, 3.46484375, ..., 3.48242188, 3.39453125,\n",
       "        3.34765625]),\n",
       " array([3.39257812, 3.40039062, 3.44921875, ..., 3.43164062, 3.35546875,\n",
       "        3.3359375 ]),\n",
       " array([3.38671875, 3.3984375 , 3.45898438, ..., 3.44335938, 3.3671875 ,\n",
       "        3.3359375 ]),\n",
       " array([3.3828125 , 3.40429688, 3.45898438, ..., 3.484375  , 3.37304688,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.40429688, 3.45703125, ..., 3.49023438, 3.36328125,\n",
       "        3.33984375]),\n",
       " array([3.39648438, 3.39648438, 3.44335938, ..., 3.48828125, 3.34765625,\n",
       "        3.33007812]),\n",
       " array([3.39257812, 3.40039062, 3.4609375 , ..., 3.49414062, 3.36328125,\n",
       "        3.33984375]),\n",
       " array([3.38867188, 3.41210938, 3.46289062, ..., 3.484375  , 3.38867188,\n",
       "        3.34570312]),\n",
       " array([3.38671875, 3.40625   , 3.4609375 , ..., 3.49023438, 3.37695312,\n",
       "        3.34179688]),\n",
       " array([3.390625  , 3.40820312, 3.46289062, ..., 3.40820312, 3.375     ,\n",
       "        3.34179688]),\n",
       " array([3.39453125, 3.41015625, 3.46289062, ..., 3.41601562, 3.38867188,\n",
       "        3.34570312]),\n",
       " array([3.39453125, 3.41015625, 3.46289062, ..., 3.48046875, 3.40234375,\n",
       "        3.3515625 ]),\n",
       " array([3.390625  , 3.3984375 , 3.45117188, ..., 3.50585938, 3.36132812,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40625   , 3.46289062, ..., 3.48632812, 3.39648438,\n",
       "        3.33789062]),\n",
       " array([3.42773438, 3.4921875 , 3.46679688, ..., 3.45117188, 3.44726562,\n",
       "        3.37109375]),\n",
       " array([3.39257812, 3.40625   , 3.46289062, ..., 3.48632812, 3.38085938,\n",
       "        3.34375   ]),\n",
       " array([3.39257812, 3.39648438, 3.453125  , ..., 3.49609375, 3.359375  ,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40429688, 3.4609375 , ..., 3.48632812, 3.37304688,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.41210938, 3.4609375 , ..., 3.49609375, 3.390625  ,\n",
       "        3.34375   ]),\n",
       " array([3.39257812, 3.41015625, 3.46484375, ..., 3.46484375, 3.37304688,\n",
       "        3.34375   ]),\n",
       " array([3.38476562, 3.3984375 , 3.45117188, ..., 3.390625  , 3.36132812,\n",
       "        3.33398438]),\n",
       " array([3.38671875, 3.40429688, 3.45703125, ..., 3.4375    , 3.38671875,\n",
       "        3.34179688]),\n",
       " array([3.39453125, 3.45703125, 3.4609375 , ..., 3.48046875, 3.39453125,\n",
       "        3.34570312]),\n",
       " array([3.38476562, 3.40039062, 3.45507812, ..., 3.37890625, 3.3671875 ,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40625   , 3.45898438, ..., 3.421875  , 3.37304688,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40625   , 3.45898438, ..., 3.41601562, 3.37890625,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40039062, 3.453125  , ..., 3.48828125, 3.36328125,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40625   , 3.45898438, ..., 3.484375  , 3.37109375,\n",
       "        3.33984375]),\n",
       " array([3.38476562, 3.40625   , 3.45703125, ..., 3.4609375 , 3.375     ,\n",
       "        3.33789062]),\n",
       " array([3.38476562, 3.40429688, 3.45703125, ..., 3.48242188, 3.36914062,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.39648438, 3.45117188, ..., 3.48632812, 3.359375  ,\n",
       "        3.33398438]),\n",
       " array([3.38671875, 3.39453125, 3.45117188, ..., 3.48632812, 3.35742188,\n",
       "        3.33203125]),\n",
       " array([3.38671875, 3.40039062, 3.45703125, ..., 3.48046875, 3.3671875 ,\n",
       "        3.3359375 ]),\n",
       " array([3.39453125, 3.40820312, 3.46484375, ..., 3.48632812, 3.38476562,\n",
       "        3.34960938]),\n",
       " array([3.38867188, 3.41015625, 3.46289062, ..., 3.484375  , 3.37695312,\n",
       "        3.34179688]),\n",
       " array([3.40625   , 3.41796875, 3.46289062, ..., 3.47265625, 3.421875  ,\n",
       "        3.35351562]),\n",
       " array([3.38671875, 3.39453125, 3.453125  , ..., 3.453125  , 3.35742188,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40429688, 3.45898438, ..., 3.49023438, 3.3671875 ,\n",
       "        3.3359375 ]),\n",
       " array([3.38476562, 3.3984375 , 3.453125  , ..., 3.45507812, 3.36914062,\n",
       "        3.3359375 ]),\n",
       " array([3.3984375 , 3.40429688, 3.39257812, ..., 3.48632812, 3.359375  ,\n",
       "        3.33984375]),\n",
       " array([3.39257812, 3.41015625, 3.46679688, ..., 3.48632812, 3.37890625,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.40234375, 3.45703125, ..., 3.48828125, 3.36328125,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.40234375, 3.45507812, ..., 3.4765625 , 3.36328125,\n",
       "        3.3359375 ]),\n",
       " array([3.38671875, 3.39648438, 3.44726562, ..., 3.48632812, 3.35742188,\n",
       "        3.33203125]),\n",
       " array([3.38671875, 3.40820312, 3.4609375 , ..., 3.38671875, 3.38085938,\n",
       "        3.34179688]),\n",
       " array([3.3828125 , 3.40039062, 3.453125  , ..., 3.48242188, 3.37304688,\n",
       "        3.3359375 ]),\n",
       " array([3.38867188, 3.40429688, 3.45507812, ..., 3.48828125, 3.36328125,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40039062, 3.45703125, ..., 3.48242188, 3.36523438,\n",
       "        3.33789062]),\n",
       " array([3.38085938, 3.39453125, 3.44921875, ..., 3.49023438, 3.359375  ,\n",
       "        3.33203125]),\n",
       " array([3.38671875, 3.3984375 , 3.453125  , ..., 3.484375  , 3.36132812,\n",
       "        3.3359375 ]),\n",
       " array([3.390625  , 3.40820312, 3.3984375 , ..., 3.48828125, 3.37695312,\n",
       "        3.34375   ]),\n",
       " array([3.38476562, 3.40429688, 3.4609375 , ..., 3.48632812, 3.37109375,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40429688, 3.4609375 , ..., 3.48632812, 3.37304688,\n",
       "        3.33789062]),\n",
       " array([3.41210938, 3.421875  , 3.45703125, ..., 3.46875   , 3.42773438,\n",
       "        3.3515625 ]),\n",
       " array([3.38867188, 3.3984375 , 3.45703125, ..., 3.421875  , 3.3671875 ,\n",
       "        3.33789062]),\n",
       " array([3.40234375, 3.41601562, 3.45507812, ..., 3.46875   , 3.421875  ,\n",
       "        3.34765625]),\n",
       " array([3.38476562, 3.40234375, 3.45898438, ..., 3.48632812, 3.36914062,\n",
       "        3.33789062]),\n",
       " array([3.38476562, 3.40429688, 3.45703125, ..., 3.46875   , 3.37695312,\n",
       "        3.33984375]),\n",
       " array([3.38671875, 3.40625   , 3.4609375 , ..., 3.484375  , 3.38085938,\n",
       "        3.34179688]),\n",
       " array([3.39257812, 3.41210938, 3.46289062, ..., 3.47460938, 3.39257812,\n",
       "        3.34570312]),\n",
       " array([3.38867188, 3.40429688, 3.45898438, ..., 3.48632812, 3.37109375,\n",
       "        3.33789062]),\n",
       " array([3.39453125, 3.40234375, 3.45898438, ..., 3.49609375, 3.36132812,\n",
       "        3.33789062]),\n",
       " array([3.38671875, 3.40234375, 3.37304688, ..., 3.49023438, 3.37304688,\n",
       "        3.33789062]),\n",
       " array([3.390625  , 3.40820312, 3.46289062, ..., 3.47070312, 3.3828125 ,\n",
       "        3.34179688]),\n",
       " array([3.39453125, 3.39257812, 3.4453125 , ..., 3.44140625, 3.3515625 ,\n",
       "        3.33203125]),\n",
       " array([3.38671875, 3.40234375, 3.45703125, ..., 3.484375  , 3.37304688,\n",
       "        3.33789062]),\n",
       " array([3.38867188, 3.41015625, 3.46484375, ..., 3.421875  , 3.38085938,\n",
       "        3.34375   ])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32c1e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new = sc.AnnData(np.array(outdict)[:,1:], obs=adata.obs, var = adata.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7124b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 324 × 11968\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster', 'batch', 'celltype', 'str_batch', 'batch_id'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'gene_name', 'id_in_vocab', 'n_counts'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3f10538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import count_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "044845ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.40625   , 3.4609375 , 3.359375  , ..., 3.48828125, 3.40234375,\n",
       "        3.33984375],\n",
       "       [3.39648438, 3.453125  , 3.5078125 , ..., 3.49023438, 3.4140625 ,\n",
       "        3.3359375 ],\n",
       "       [3.39257812, 3.44140625, 3.34375   , ..., 3.50195312, 3.34960938,\n",
       "        3.33007812],\n",
       "       ...,\n",
       "       [3.39257812, 3.4453125 , 3.34375   , ..., 3.44140625, 3.3515625 ,\n",
       "        3.33203125],\n",
       "       [3.40234375, 3.45703125, 3.50585938, ..., 3.484375  , 3.37304688,\n",
       "        3.33789062],\n",
       "       [3.41015625, 3.46484375, 3.3671875 , ..., 3.421875  , 3.38085938,\n",
       "        3.34375   ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_new.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d9b2253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - count_nonzero(adata_new.X) / float(adata_new.X.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f30fe87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new.write_h5ad(\"spatial_imputation_new.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0458c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb4368c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_list = []\n",
    "pval_list = []\n",
    "for item in adata.var_names:\n",
    "    adata1 = adata[:,item]\n",
    "    adata2 = adata_new[:,item]\n",
    "    cor, pval = scipy.stats.spearmanr(np.array(adata1.X.todense().T)[0], np.array(adata2.X.T)[0])\n",
    "    cor_list.append(cor)\n",
    "    pval_list.append(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91dcdf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05923405337968228,\n",
       " -0.3278977871913318,\n",
       " 0.5721037791433999,\n",
       " 0.7985836063396072,\n",
       " 0.41041529376767677,\n",
       " 0.7802770012737438,\n",
       " 0.4115730318542943,\n",
       " 0.46244619197024156,\n",
       " 0.24946992605678553,\n",
       " 0.5003719870234385,\n",
       " 0.12814738424749345,\n",
       " 0.5374543582662592,\n",
       " -0.32085680293082713,\n",
       " -0.06763803562165885,\n",
       " 0.11181003023607977,\n",
       " 0.3141214554809655,\n",
       " -0.08822641220638666,\n",
       " 0.7936769651600385,\n",
       " 0.21787716355806538,\n",
       " 0.257106008914113,\n",
       " 0.6633435439076554,\n",
       " 0.20109670382007663,\n",
       " 0.7637324017950179,\n",
       " 0.45570515399834893,\n",
       " 0.8052275898971802,\n",
       " 0.1949541354167539,\n",
       " 0.2624694417383895,\n",
       " 0.16002564731660548,\n",
       " 0.7476039020244019,\n",
       " 0.712051634969082,\n",
       " -0.0013696567683885769,\n",
       " -0.037291966574378894,\n",
       " -0.315761783424724,\n",
       " 0.19003720743239,\n",
       " 0.3717377799739006,\n",
       " -0.2905242560808739,\n",
       " 0.37858442809578685,\n",
       " 0.7016812242163211,\n",
       " 0.8357859727244613,\n",
       " -0.16796143321442472,\n",
       " 0.6578598099500411,\n",
       " 0.16166775266927197,\n",
       " 0.7200851395199765,\n",
       " 0.7936185226549637,\n",
       " -0.056840690492562025,\n",
       " -0.1332562083668741,\n",
       " 0.5553929825416458,\n",
       " 0.6443438741137861,\n",
       " 0.0001443257517302208,\n",
       " 0.517177633893601,\n",
       " 0.6007302170109098,\n",
       " 0.6099923951342535,\n",
       " -0.04282353403796474,\n",
       " 0.813943839852517,\n",
       " 0.8755849535188674,\n",
       " 0.15009252333515746,\n",
       " -0.28607681318937694,\n",
       " 0.49263932682543143,\n",
       " 0.7236567586292271,\n",
       " 0.7397566651102319,\n",
       " -0.5675332886879412,\n",
       " -0.08552278262439045,\n",
       " 0.3075499168182981,\n",
       " -0.018024279889219123,\n",
       " 0.8979974206769744,\n",
       " 0.8405693337524558,\n",
       " -0.21353921587421287,\n",
       " 0.15077769773757635,\n",
       " 0.1998727610977248,\n",
       " 0.6928459694787091,\n",
       " 0.7125970226016373,\n",
       " 0.407087046446398,\n",
       " 0.7115960618848731,\n",
       " 0.80442641340967,\n",
       " 0.729278742566309,\n",
       " -0.06406665889014095,\n",
       " 0.4582717342231941,\n",
       " 0.2455482971211578,\n",
       " 0.5049830292052978,\n",
       " 0.6359973027703161,\n",
       " 0.2459982864168193,\n",
       " 0.04071433875468733,\n",
       " -0.19366620870026416,\n",
       " -0.028104291460023478,\n",
       " -0.19955471047194775,\n",
       " -0.23003920050271004,\n",
       " 0.4997997533362803,\n",
       " 0.7899789539586317,\n",
       " 0.6647549333639463,\n",
       " 0.5527049380513097,\n",
       " 0.4893510552604989,\n",
       " 0.4278588897506735,\n",
       " 0.057581526120967876,\n",
       " 0.3608805302965764,\n",
       " 0.3251947600512717,\n",
       " 0.5961897465329723,\n",
       " 0.70806001819773,\n",
       " 0.31358962743258156,\n",
       " -0.44573492122837255,\n",
       " 0.6805421309418819,\n",
       " 0.4833710161893982,\n",
       " 0.18641413031423648,\n",
       " 0.10960372580363545,\n",
       " -0.7627249978678721,\n",
       " -0.04460862281571573,\n",
       " 0.15666431789567856,\n",
       " 0.15046392669782363,\n",
       " 0.636860123591716,\n",
       " 0.6140570453108334,\n",
       " -0.15273520518410127,\n",
       " 0.21594931216900096,\n",
       " 0.2166221185805322,\n",
       " 0.8246147785206348,\n",
       " 0.8936646961055965,\n",
       " 0.25932233577234926,\n",
       " 0.28868428691098413,\n",
       " 0.8039244811702393,\n",
       " 0.6518309472060217,\n",
       " 0.4489634620507558,\n",
       " -0.076369645920853,\n",
       " 0.4907427954816037,\n",
       " 0.5759588971634119,\n",
       " 0.13029701327373763,\n",
       " -0.04747052387087359,\n",
       " 0.14292928407441005,\n",
       " 0.23039324355379837,\n",
       " -0.03086012807612124,\n",
       " -0.26913522061494216,\n",
       " -0.23482828587377355,\n",
       " 0.16941449500974945,\n",
       " 0.14111637974525557,\n",
       " 0.24545992962296678,\n",
       " 0.824536956988882,\n",
       " 0.3516747111976359,\n",
       " 0.40862622417428185,\n",
       " -0.076025740865868,\n",
       " -0.000554268699668431,\n",
       " 0.27544394622460694,\n",
       " -0.21497189939955216,\n",
       " 0.35911995134199143,\n",
       " 0.053652556373108576,\n",
       " 0.6190209574322192,\n",
       " -0.19002833788685525,\n",
       " 0.19344581857518006,\n",
       " 0.12085396014382524,\n",
       " 0.279539220359816,\n",
       " -0.026830431269088767,\n",
       " 0.3114837943209909,\n",
       " -0.06052925385356125,\n",
       " 0.45927999538676423,\n",
       " 0.4806804507579754,\n",
       " 0.13292320278203992,\n",
       " 0.3441545226108972,\n",
       " 0.35429298796311076,\n",
       " 0.5789151537026519,\n",
       " 0.2801518564103225,\n",
       " -0.07169876156007765,\n",
       " 0.711200704229315,\n",
       " -0.3010177912846245,\n",
       " 0.26805403300740926,\n",
       " 0.021956571623587745,\n",
       " 0.5561443457111057,\n",
       " 0.5749998826820082,\n",
       " 0.420611177418788,\n",
       " 0.4019306591100254,\n",
       " -0.12266688129212341,\n",
       " -0.12071755326168956,\n",
       " 0.4548633632233278,\n",
       " 0.7814639764645599,\n",
       " 0.35130304814995145,\n",
       " 0.1604327033030817,\n",
       " 0.299992839383467,\n",
       " 0.7728866027467559,\n",
       " 0.1291190754521192,\n",
       " 0.5905123116517822,\n",
       " 0.04458241264303001,\n",
       " 0.7592933292872129,\n",
       " 0.4624213846701823,\n",
       " -0.09354548403977316,\n",
       " 0.07314915368049546,\n",
       " 0.0614228794043171,\n",
       " 0.1431017980092283,\n",
       " 0.2882901170009739,\n",
       " 0.5592033474026636,\n",
       " 0.6947667686069413,\n",
       " 0.5294953883629115,\n",
       " 0.10942958081953173,\n",
       " 0.4269900729839161,\n",
       " -0.4654909115978222,\n",
       " 0.300772397799435,\n",
       " 0.037757881122792096,\n",
       " 0.6269196141136,\n",
       " -0.12763796903581817,\n",
       " -0.08797487958032507,\n",
       " 0.5320762313140106,\n",
       " 0.3854857069290781,\n",
       " 0.42538964854280953,\n",
       " 0.21794498682944172,\n",
       " -0.01761999602467547,\n",
       " 0.718708661452419,\n",
       " -0.3467246575290775,\n",
       " 0.4901753629236035,\n",
       " 0.47045094039678326,\n",
       " 0.15354448665765716,\n",
       " 0.4258865253941967,\n",
       " -0.08441865248838604,\n",
       " 0.6461734753221637,\n",
       " 0.549547515392733,\n",
       " 0.5187540846063948,\n",
       " 0.5321017796181876,\n",
       " 0.7627714015101524,\n",
       " 0.36071564865047223,\n",
       " 0.2781875450440969,\n",
       " 0.6612627841568237,\n",
       " 0.3747570919948683,\n",
       " 0.6474386614907579,\n",
       " 0.22016012315375494,\n",
       " 0.00013184557859968009,\n",
       " -0.4674016669171879,\n",
       " -0.029049650072107427,\n",
       " -0.17704568742783802,\n",
       " 0.05213227684256343,\n",
       " 0.16003142312428797,\n",
       " 0.5513039361942333,\n",
       " 0.09648796884378423,\n",
       " -0.4183605488740391,\n",
       " 0.32384492475521687,\n",
       " -0.14536302494914238,\n",
       " 0.4115053531676871,\n",
       " 0.8164416344327604,\n",
       " 0.5829426540116796,\n",
       " 0.5440651533972606,\n",
       " 0.34422025497571956,\n",
       " 0.23327341161533735,\n",
       " -0.28543382189700567,\n",
       " 0.2994905279606754,\n",
       " 0.18798710777079683,\n",
       " 0.45833132968421564,\n",
       " 0.0147206796716975,\n",
       " -0.09637867259336605,\n",
       " 0.365793403568989,\n",
       " 0.28462050885384743,\n",
       " 0.5465184842839893,\n",
       " 0.12129519826559607,\n",
       " 0.02526466960633782,\n",
       " 0.7289439064373309,\n",
       " 0.2749109260105852,\n",
       " 0.05136860696616946,\n",
       " -0.2657078317483215,\n",
       " 0.1955545108832201,\n",
       " 0.12156522000842737,\n",
       " 0.6036500884751324,\n",
       " 0.3092599368018738,\n",
       " 0.4188688267249324,\n",
       " 0.8148021813516028,\n",
       " 0.2786278131376775,\n",
       " 0.08452518390025605,\n",
       " 0.5324803794764639,\n",
       " -0.45160533547374837,\n",
       " 0.6061492811781508,\n",
       " 0.8201054351732158,\n",
       " 0.5554341806327076,\n",
       " 0.20328751546223017,\n",
       " -0.020023726294549307,\n",
       " 0.5624206212268511,\n",
       " 0.632737479866027,\n",
       " 0.20414971638209403,\n",
       " 0.49068574354627026,\n",
       " 0.1358542673379031,\n",
       " 0.6532895278256367,\n",
       " 0.34334975071801305,\n",
       " -0.01620995221735803,\n",
       " 0.6994467053630943,\n",
       " 0.8579173669399252,\n",
       " 0.19853817887249414,\n",
       " 0.27660152886367195,\n",
       " 0.6506915579295897,\n",
       " 0.04959677206887923,\n",
       " 0.643871770254192,\n",
       " -0.12317417075046128,\n",
       " 0.6437432636937878,\n",
       " 0.3681445956480386,\n",
       " 0.7225250286679225,\n",
       " 0.6666776026834779,\n",
       " 0.34557561149011906,\n",
       " 0.8576396899960328,\n",
       " 0.21798981819755064,\n",
       " 0.23867972561865095,\n",
       " -0.1329333248948405,\n",
       " 0.6720356858983048,\n",
       " -0.030045262776163824,\n",
       " 0.6827211100947572,\n",
       " -0.2110820151692196,\n",
       " 0.8198380313164265,\n",
       " 0.6452749770007209,\n",
       " 0.45033757923391554,\n",
       " -0.025431605645495292,\n",
       " 0.33128791192072304,\n",
       " 0.3665406511747207,\n",
       " -0.222532364163468,\n",
       " 0.6888263126982922,\n",
       " -0.08192166052731759,\n",
       " -0.21923656556140944,\n",
       " 0.31335178575473893,\n",
       " 0.5965485681122721,\n",
       " 0.026534409386903064,\n",
       " 0.2816982112356352,\n",
       " 0.13013221033575398,\n",
       " 0.1909558471019724,\n",
       " 0.44570985794628176,\n",
       " -0.22258781872026434,\n",
       " 0.6821538556213287,\n",
       " 0.03620611118814831,\n",
       " 0.28486946324104984,\n",
       " 0.18856838855745112,\n",
       " 0.7418687654153718,\n",
       " 0.181020094379242,\n",
       " 0.7274778644322808,\n",
       " 0.23532916630918013,\n",
       " 0.6916598236172944,\n",
       " 0.17921836370244892,\n",
       " 0.006072788042360402,\n",
       " 0.7278904950417149,\n",
       " -0.3069388586388373,\n",
       " 0.7554389573633193,\n",
       " 0.22741016885018342,\n",
       " 0.6376186020798296,\n",
       " 0.7015439957402297,\n",
       " -0.42927158615735217,\n",
       " 0.6290830468165357,\n",
       " -0.026781515475333858,\n",
       " 0.3849357643479832,\n",
       " -0.35719898774109876,\n",
       " 0.07321800415721821,\n",
       " -0.25366051523535443,\n",
       " 0.5124279493496638,\n",
       " 0.1508539381086184,\n",
       " -0.2524120195049814,\n",
       " -0.05502121612975967,\n",
       " 0.02503159144026047,\n",
       " 0.1877247833673323,\n",
       " 0.8241757693220784,\n",
       " -0.09181957948802827,\n",
       " 0.13622119989661355,\n",
       " -0.09598419481864902,\n",
       " 0.07182620610948189,\n",
       " -0.2526543167967486,\n",
       " 0.6644847005494309,\n",
       " 0.7266333305186199,\n",
       " 0.2592885735523526,\n",
       " 0.3488311392537236,\n",
       " 0.724018524476715,\n",
       " -0.3404533740055316,\n",
       " 0.5245996599429805,\n",
       " 0.4491828324890508,\n",
       " 0.04159460548434719,\n",
       " -0.06635832697908982,\n",
       " 0.0001648223186811308,\n",
       " 0.7822825987176102,\n",
       " 0.15994955848542206,\n",
       " 0.1541825732312171,\n",
       " 0.5170828990114157,\n",
       " 0.5436693920955759,\n",
       " 0.365928526846516,\n",
       " 0.6474474298629292,\n",
       " 0.5402486609697225,\n",
       " 0.1655729857271249,\n",
       " 0.7376560549543967,\n",
       " -0.21714557066528817,\n",
       " 0.28540272472278994,\n",
       " 0.5454155857012924,\n",
       " -0.09194926227626064,\n",
       " 0.05900794775241946,\n",
       " 0.4300749828675515,\n",
       " 0.23923742465370024,\n",
       " 0.023380492930283263,\n",
       " 0.2697300687650399,\n",
       " 0.21109239989269696,\n",
       " 0.7264403121001921,\n",
       " 0.35242529390205024,\n",
       " 0.6338393146328064,\n",
       " 0.24576316683762053,\n",
       " 0.13636871809556686,\n",
       " 0.06294173371520558,\n",
       " 0.15365423999158323,\n",
       " 0.28629468557064225,\n",
       " -0.2294409773506191,\n",
       " 0.6437904561456004,\n",
       " 0.006807640327133157,\n",
       " -0.16364469488201627,\n",
       " -0.6882678205085416,\n",
       " -0.06363017740166492,\n",
       " 0.27185885700442075,\n",
       " 0.5434687402833196,\n",
       " 0.3259617166126877,\n",
       " 0.006053124408035237,\n",
       " 0.9197565662093921,\n",
       " 0.25057616959576384,\n",
       " 0.416901209433883,\n",
       " 0.6291173252994733,\n",
       " -0.20947932004075884,\n",
       " 0.6805665288994015,\n",
       " -0.08060681674372579,\n",
       " 0.7639716425027463,\n",
       " 0.5375658502147261,\n",
       " 0.1526762798091368,\n",
       " -0.3971606570776351,\n",
       " 0.6819920480483312,\n",
       " -0.003305820088529868,\n",
       " -0.26109227572448923,\n",
       " 0.34895492707596687,\n",
       " -0.16727207883647321,\n",
       " 0.14020931088728414,\n",
       " 0.4821782038969297,\n",
       " 0.580340150271962,\n",
       " 0.004666119936046571,\n",
       " -0.06850071914126533,\n",
       " 0.20466898336668057,\n",
       " 0.2816826309371818,\n",
       " 0.18370354880671794,\n",
       " -0.20394407517880225,\n",
       " 0.24380495795656068,\n",
       " 0.05381294573558089,\n",
       " 0.03643836361303039,\n",
       " 0.0021552845624235434,\n",
       " 0.5466631230958755,\n",
       " 0.8245451419757539,\n",
       " -0.24270963317236058,\n",
       " -0.10896915881692205,\n",
       " 0.15452929441727087,\n",
       " 0.6339873485856039,\n",
       " 0.27913865803893195,\n",
       " 0.5277961788913197,\n",
       " 0.37466969609165546,\n",
       " 0.7456329796001471,\n",
       " 0.8495904689881147,\n",
       " 0.9199968899118842,\n",
       " 0.7773498924945614,\n",
       " 0.12115183351961924,\n",
       " 0.35973173847755674,\n",
       " 0.7487925855707441,\n",
       " 0.49419784716632803,\n",
       " -0.09039386739967316,\n",
       " 0.6415248753022342,\n",
       " 0.7363858732548383,\n",
       " -0.12680812469976108,\n",
       " -0.19740716174410572,\n",
       " 0.08130642458461283,\n",
       " 0.924055243733508,\n",
       " 0.8132638315472909,\n",
       " 0.5817528794078966,\n",
       " 0.2952206720623519,\n",
       " 0.8698378140516132,\n",
       " 0.5319897906973159,\n",
       " 0.29831068157411356,\n",
       " 0.23051639175648492,\n",
       " 0.7825931709238321,\n",
       " 0.4308224465276915,\n",
       " -0.00405475662280758,\n",
       " -0.16660161408153687,\n",
       " 0.42473848893329186,\n",
       " 0.44978336182456574,\n",
       " 0.5525013958250563,\n",
       " 0.7950614699604114,\n",
       " 0.8820976055252999,\n",
       " 0.7191486765727764,\n",
       " 0.5015506879454164,\n",
       " 0.7892827047366548,\n",
       " 0.23763225846981062,\n",
       " 0.33818390004592996,\n",
       " 0.10770893769553305,\n",
       " -0.007635117245353209,\n",
       " 0.6277878308978521,\n",
       " 0.6143720989298342,\n",
       " 0.30117540397529363,\n",
       " 0.8597867976466129,\n",
       " 0.2111526338958251,\n",
       " -0.3154240830934835,\n",
       " 0.643748645966806,\n",
       " 0.17929021730902278,\n",
       " 0.4370177629765872,\n",
       " 0.07368215377572279,\n",
       " 0.5989737488314987,\n",
       " 0.6666964638941927,\n",
       " 0.7267629285960435,\n",
       " 0.693425274795851,\n",
       " 0.49941009540672043,\n",
       " 0.6870774973333306,\n",
       " 0.26211698114681203,\n",
       " 0.7492264979306723,\n",
       " -0.00917718816316584,\n",
       " -0.43095273057189726,\n",
       " 0.4693629909149876,\n",
       " 0.5124158990982629,\n",
       " 0.2150478580913709,\n",
       " 0.12592062233999782,\n",
       " 0.7721191037982533,\n",
       " -0.08589797438597627,\n",
       " 0.41895774737603414,\n",
       " 0.43954368037293956,\n",
       " 0.34884428842611404,\n",
       " 0.29218198186675853,\n",
       " -0.026761650855229004,\n",
       " 0.5479882514956874,\n",
       " 0.8064545275117418,\n",
       " -0.15967311691466046,\n",
       " 0.7102683049590538,\n",
       " 0.915795707604317,\n",
       " 0.04020190114234861,\n",
       " -0.056458947633004596,\n",
       " 0.265578225104883,\n",
       " 0.6806610748436024,\n",
       " 0.20110118067316074,\n",
       " 0.7973833599435765,\n",
       " 0.058280780423155674,\n",
       " 0.049288611197955814,\n",
       " 0.35633809045779924,\n",
       " -0.2740765715216826,\n",
       " 0.8750237227334282,\n",
       " 0.8094885285836584,\n",
       " 0.23182882273177077,\n",
       " 0.7411209263834726,\n",
       " 0.6650442597774424,\n",
       " 0.6660519515314326,\n",
       " 0.0945651453575513,\n",
       " 0.60748155022763,\n",
       " 0.2041600220538759,\n",
       " 0.6383479116300549,\n",
       " 0.33029852259327,\n",
       " 0.6070109830444681,\n",
       " 0.41054386962878436,\n",
       " 0.3728135380557877,\n",
       " 0.5820598208202863,\n",
       " -0.7383500724866127,\n",
       " 0.5547812276750191,\n",
       " 0.3140376677709201,\n",
       " 0.5930808593183187,\n",
       " 0.6220022948608996,\n",
       " 0.7402455493521466,\n",
       " 0.919135940247181,\n",
       " 0.7394985201853109,\n",
       " 0.06430979219607709,\n",
       " 0.8483606810152526,\n",
       " 0.6697375260640065,\n",
       " 0.314074011150516,\n",
       " -0.6263064750084081,\n",
       " 0.056399497378978876,\n",
       " -0.13116125725500413,\n",
       " 0.8917928574077199,\n",
       " 0.11188652784115127,\n",
       " 0.5041211340698043,\n",
       " 0.03537173832486241,\n",
       " 0.8623081404803052,\n",
       " -0.12995163890475123,\n",
       " 0.7902257171947071,\n",
       " 0.14920023051424938,\n",
       " 0.7141573815658843,\n",
       " -0.0036882908300808603,\n",
       " -0.35233731599585283,\n",
       " 0.1192091833986255,\n",
       " -0.16176574573126484,\n",
       " 0.02184635984738579,\n",
       " -0.27215632079548835,\n",
       " -0.13004703648582067,\n",
       " -0.004877487200052687,\n",
       " 0.5654963118818493,\n",
       " 0.21765257747822855,\n",
       " 0.6314669633161775,\n",
       " 0.041593876432938055,\n",
       " 0.3812202071647326,\n",
       " 0.42575159451400585,\n",
       " 0.26314426907968563,\n",
       " 0.6787744617783252,\n",
       " 0.19959824851658312,\n",
       " 0.2612776053155054,\n",
       " 0.12323231475526263,\n",
       " 0.5495269101287589,\n",
       " 0.22869811765921577,\n",
       " 0.924865333630379,\n",
       " -0.1344142738844542,\n",
       " 0.26847932056598695,\n",
       " 0.7610841447067225,\n",
       " -0.4085061872533958,\n",
       " 0.7290938955045199,\n",
       " -0.09344240497853262,\n",
       " -0.7103236435073113,\n",
       " -0.009501415203322754,\n",
       " 0.882256887075989,\n",
       " 0.6187266523942964,\n",
       " 0.06558899039481696,\n",
       " 0.20561871567276216,\n",
       " -0.053174259072169175,\n",
       " 0.41239656391094515,\n",
       " 0.5167410068048286,\n",
       " 0.552230322699171,\n",
       " -0.0015710945952394295,\n",
       " 0.38293391055778825,\n",
       " -0.25608701317949245,\n",
       " -0.1921717159205374,\n",
       " 0.717425298193132,\n",
       " 0.6147653431896799,\n",
       " 0.9084350800329828,\n",
       " -0.04064347929645692,\n",
       " -0.23026617172341632,\n",
       " -0.11937881267230199,\n",
       " -0.05758334976011218,\n",
       " 0.35628952649013346,\n",
       " 0.24619946300552784,\n",
       " 0.13165383237899095,\n",
       " 0.4666357859496582,\n",
       " 0.5420115559250942,\n",
       " 0.5008110007213665,\n",
       " 0.4792459053575292,\n",
       " 0.45858254869589954,\n",
       " 0.21539341760713013,\n",
       " 0.28558471900040416,\n",
       " 0.5653721184932544,\n",
       " -0.025974842170803144,\n",
       " 0.19279406207849803,\n",
       " 0.5181191267701316,\n",
       " 0.2686200555272512,\n",
       " 0.6621906444675809,\n",
       " 0.511863781016354,\n",
       " 0.675066503825926,\n",
       " 0.8628248616839382,\n",
       " 0.11458670014303084,\n",
       " 0.6507155479537394,\n",
       " 0.7229722281758512,\n",
       " 0.13707597916272968,\n",
       " 0.11546564932649946,\n",
       " 0.11371619244637239,\n",
       " -0.3976145241068047,\n",
       " 0.3451308345527094,\n",
       " 0.08668381037287053,\n",
       " 0.30648285865773234,\n",
       " 0.7882706886102009,\n",
       " 0.8736220905612705,\n",
       " 0.10875226945549722,\n",
       " 0.6043868698167225,\n",
       " 0.10422264733514155,\n",
       " 0.33144693014894233,\n",
       " 0.1792931103353633,\n",
       " 0.7244162233799245,\n",
       " 0.1746796952630434,\n",
       " 0.7731071946111518,\n",
       " 0.03302195975531718,\n",
       " 0.2191954441018437,\n",
       " 0.7734733656177356,\n",
       " -0.8118894459254458,\n",
       " 0.05529526223582491,\n",
       " 0.2529192793197872,\n",
       " 0.12312440394126291,\n",
       " -0.011583010459088348,\n",
       " 0.3956496118210298,\n",
       " 0.5202614696239245,\n",
       " 0.34078167709175167,\n",
       " 0.8385166372970264,\n",
       " -0.031462936394347274,\n",
       " -0.25348557798718196,\n",
       " 0.3101347407419666,\n",
       " 0.9232537207811709,\n",
       " 0.6921594651804615,\n",
       " -0.1352913513928336,\n",
       " 0.7500512013136911,\n",
       " 0.4604802284266344,\n",
       " 0.20238642833691384,\n",
       " 0.2687432417648901,\n",
       " 0.37621532876961133,\n",
       " 0.11814673107063954,\n",
       " -0.16556399647250275,\n",
       " 0.4209650395259003,\n",
       " 0.47894034663226426,\n",
       " 0.6614560092616978,\n",
       " 0.8704853410519999,\n",
       " -0.2357429006726438,\n",
       " 0.1488687500059552,\n",
       " 0.8181571660460161,\n",
       " -0.040434469274482604,\n",
       " 0.7233825084621767,\n",
       " 0.5814943180845372,\n",
       " 0.44051821299176686,\n",
       " 0.678669147004114,\n",
       " 0.22038494066053463,\n",
       " 0.7027106468777469,\n",
       " 0.284087924958708,\n",
       " 0.6709165837579601,\n",
       " 0.36257837175929236,\n",
       " -0.18620171148145392,\n",
       " 0.7663096695319996,\n",
       " 0.6981074029458479,\n",
       " 0.2855727080301439,\n",
       " 0.2702463334517444,\n",
       " 0.2013716493504689,\n",
       " 0.2591324455876386,\n",
       " -0.1140607924418873,\n",
       " 0.2936278844164633,\n",
       " 0.03641697987638623,\n",
       " 0.7602198144494059,\n",
       " 0.529183371517946,\n",
       " 0.6387347120791973,\n",
       " 0.07793386642984741,\n",
       " 0.1156074499678445,\n",
       " 0.6305069594847074,\n",
       " -0.31466968694504904,\n",
       " 0.6492220233305598,\n",
       " 0.8479140756615005,\n",
       " 0.3580383385530903,\n",
       " 0.44023716157279275,\n",
       " 0.18405858907576186,\n",
       " -0.00028557383154407737,\n",
       " -0.03372939141858937,\n",
       " 0.7922392013993045,\n",
       " 0.09586409557674595,\n",
       " 0.5538615113304235,\n",
       " 0.8539015613789448,\n",
       " 0.4896554348723729,\n",
       " -0.32397494856422987,\n",
       " 0.3023740735955376,\n",
       " 0.909552930640159,\n",
       " -0.2007300000556516,\n",
       " 0.5628730793514771,\n",
       " -0.0004964171744850376,\n",
       " 0.3772860482693566,\n",
       " -0.6208237121793024,\n",
       " -0.06652499032525201,\n",
       " 0.8567819704951941,\n",
       " 0.0694703275974478,\n",
       " 0.14679097618344522,\n",
       " 0.49480206447400016,\n",
       " 0.284086329285174,\n",
       " 0.7346455432272897,\n",
       " 0.05417487028095742,\n",
       " 0.3613538356720086,\n",
       " 0.3695997217480988,\n",
       " 0.013926555290029416,\n",
       " -0.3515654437599315,\n",
       " 0.48192843374248745,\n",
       " 0.12913184001300665,\n",
       " 0.42039761716140583,\n",
       " 0.8383717478819835,\n",
       " 0.1822317907576996,\n",
       " 0.8029496801126766,\n",
       " 0.16167133825493632,\n",
       " -0.3825435093236893,\n",
       " 0.7719016128548196,\n",
       " 0.5403565101155187,\n",
       " 0.32689371684782526,\n",
       " 0.4461974083727949,\n",
       " 0.0586886516665281,\n",
       " 0.6937535070531977,\n",
       " 0.16805416540372292,\n",
       " -0.33017441047369306,\n",
       " -0.7391891283874027,\n",
       " 0.38818791683311676,\n",
       " 0.21465507172849427,\n",
       " -0.05843289464733863,\n",
       " -0.05358379358836649,\n",
       " 0.1317306914009386,\n",
       " -0.03039457345440167,\n",
       " 0.6552625614760745,\n",
       " -0.024143646767707368,\n",
       " 0.7464569303499989,\n",
       " 0.3160347953994318,\n",
       " -0.1824265191868028,\n",
       " 0.713970154203827,\n",
       " 0.1914835953901087,\n",
       " 0.8143761719810357,\n",
       " 0.6500093968910279,\n",
       " -0.06002150290012564,\n",
       " -0.5959006271355608,\n",
       " 0.008856586453416282,\n",
       " 0.634698273719806,\n",
       " -0.04136018553983201,\n",
       " 0.6583528869794463,\n",
       " 0.6627915544116694,\n",
       " 0.008123923665971705,\n",
       " 0.20692774133400893,\n",
       " -0.0460244294790165,\n",
       " 0.14483317115529026,\n",
       " 0.15350106402313163,\n",
       " 0.4237191848116284,\n",
       " 0.010945106038644705,\n",
       " 0.7456633788178755,\n",
       " 0.45057847185654376,\n",
       " 0.3404480847325294,\n",
       " 0.8366371287428228,\n",
       " 0.31128953577119545,\n",
       " -0.30282177321644865,\n",
       " 0.8069247629197877,\n",
       " -0.005375284298790901,\n",
       " 0.3719149000332915,\n",
       " 0.7373045004136052,\n",
       " 0.7766854061378201,\n",
       " 0.13942098991316046,\n",
       " -0.11052138422022821,\n",
       " 0.7768613893218471,\n",
       " 0.6007899466987141,\n",
       " 0.6696827272261638,\n",
       " -0.10360289740420814,\n",
       " 0.5242189905470106,\n",
       " 0.45705640882188014,\n",
       " -0.0777186726344698,\n",
       " 0.8181513510409071,\n",
       " 0.568016597300741,\n",
       " 0.057255776278178426,\n",
       " -0.031244124493183485,\n",
       " 0.021526818398093863,\n",
       " 0.47934354454720185,\n",
       " 0.08433908710136519,\n",
       " 0.5600234810909995,\n",
       " 0.15736102659571471,\n",
       " -0.03469308877179281,\n",
       " 0.682737269629656,\n",
       " -0.33395376027123613,\n",
       " 0.8991332538914006,\n",
       " 0.7072382542353292,\n",
       " -0.011917310656301854,\n",
       " 0.6468201954580975,\n",
       " 0.8146256411703823,\n",
       " 0.8393369731798184,\n",
       " -0.43120363695887803,\n",
       " 0.3022926857442172,\n",
       " 0.03295259738925392,\n",
       " 0.044145997229899786,\n",
       " 0.22072307001828922,\n",
       " 0.3612549276498306,\n",
       " 0.8584845636352623,\n",
       " 0.5576774600675841,\n",
       " -0.31420294214980904,\n",
       " -0.06509229741216743,\n",
       " 0.6997202344734992,\n",
       " -0.024263890274018443,\n",
       " -0.30928223320994835,\n",
       " 0.5171427325835067,\n",
       " 0.32814442934158183,\n",
       " 0.6356258703355518,\n",
       " 0.27352641262395083,\n",
       " 0.818362382020473,\n",
       " 0.617323618115826,\n",
       " 0.6752755436157118,\n",
       " 0.6399786451171096,\n",
       " 0.5242454379560233,\n",
       " 0.35593708918546346,\n",
       " 0.46707858328234964,\n",
       " 0.7904630173988113,\n",
       " 0.5240488425607717,\n",
       " 0.7722353825969166,\n",
       " -0.10103694501443,\n",
       " 0.7429195595017452,\n",
       " 0.17181937333712852,\n",
       " 0.5722787614278633,\n",
       " 0.70960370147495,\n",
       " 0.4084760046153838,\n",
       " 0.8016407762861845,\n",
       " 0.11593677759565854,\n",
       " 0.7268381826460759,\n",
       " 0.20823108012958147,\n",
       " 0.6760100485218298,\n",
       " 0.4788004960308303,\n",
       " -0.28162365121203886,\n",
       " 0.2011373037898383,\n",
       " 0.31434355646349493,\n",
       " 0.21170615387541522,\n",
       " 0.92092469715609,\n",
       " -0.04032252731922192,\n",
       " 0.1470902345665083,\n",
       " 0.32939686354795544,\n",
       " 0.691932199753407,\n",
       " 0.18227059643153448,\n",
       " 0.27953892921571327,\n",
       " -0.09067530329098103,\n",
       " -0.0017155054506409933,\n",
       " 0.5805401374723134,\n",
       " -0.24657641038353664,\n",
       " 0.03713928748625609,\n",
       " -0.39169963155917364,\n",
       " 0.6121059321742807,\n",
       " 0.12411329098304479,\n",
       " -0.13614572432951258,\n",
       " 0.07094031032862977,\n",
       " 0.7404892618421278,\n",
       " 0.17922870572343516,\n",
       " 0.8243319334422765,\n",
       " -0.19705426758362324,\n",
       " 0.15745567066118174,\n",
       " 0.8637193837622165,\n",
       " 0.3708812729590515,\n",
       " -0.1837688410472106,\n",
       " 0.3770035523857488,\n",
       " 0.40596543240446387,\n",
       " -0.5474595392885929,\n",
       " -0.4497576224313528,\n",
       " -0.016187190882515964,\n",
       " 0.5906970765642997,\n",
       " 0.4818703556999379,\n",
       " 0.13065649173997262,\n",
       " 0.3277843659689781,\n",
       " 0.5350397823037024,\n",
       " 0.12058605930753409,\n",
       " -0.10713278963346597,\n",
       " 0.11635331678075472,\n",
       " 0.00878215022057805,\n",
       " 0.3527426090237046,\n",
       " 0.5068857717147357,\n",
       " 0.043457084084247116,\n",
       " 0.3454077843827127,\n",
       " 0.6969818679940093,\n",
       " 0.2372561355941962,\n",
       " 0.5291049081837946,\n",
       " 0.5285331226704182,\n",
       " 0.2462409280015074,\n",
       " 0.2829186256368932,\n",
       " 0.7414758242700858,\n",
       " 0.24976767737147343,\n",
       " 0.4638606319879655,\n",
       " 0.49155618751716196,\n",
       " 0.6102171320139348,\n",
       " 0.8406287335648943,\n",
       " 0.2981480840043774,\n",
       " 0.5308217508097293,\n",
       " 0.12947275703609523,\n",
       " 0.5872652160982562,\n",
       " 0.6026473125205057,\n",
       " -0.07835148867913523,\n",
       " 0.2010933835878054,\n",
       " 0.6617946250010702,\n",
       " 0.40377507481793695,\n",
       " 0.8533564243062567,\n",
       " 0.8761803590901646,\n",
       " -0.04493489444726838,\n",
       " 0.1074927659217837,\n",
       " -0.1832244268508643,\n",
       " 0.6476177093647782,\n",
       " -0.11995924167384771,\n",
       " 0.31429085680847213,\n",
       " 0.27939059295024393,\n",
       " 0.14315246832435208,\n",
       " 0.28026066974868485,\n",
       " 0.5526416505349502,\n",
       " 0.6822937090987987,\n",
       " -0.35996443896340796,\n",
       " 0.5099516534776015,\n",
       " 0.42862269960978866,\n",
       " 0.7579281123445671,\n",
       " 0.08245137566081702,\n",
       " -0.3157751870208887,\n",
       " 0.6893528621973853,\n",
       " 0.2512494374247757,\n",
       " 0.07272125176870263,\n",
       " -0.1483559560843962,\n",
       " 0.1049966982413372,\n",
       " 0.8279204414580106,\n",
       " -0.2901331564917869,\n",
       " -0.18179587380365625,\n",
       " 0.6328594361668605,\n",
       " 0.8435470456565262,\n",
       " -0.013225554400671103,\n",
       " 0.6505603053974787,\n",
       " -0.0014204010410117486,\n",
       " 0.3065209168096921,\n",
       " 0.008595295657812446,\n",
       " 0.34796754512590394,\n",
       " 0.7860968378613159,\n",
       " 0.328263823103669,\n",
       " -0.10020886956646215,\n",
       " 0.7917791467394639,\n",
       " 0.3943185863988559,\n",
       " 0.31759970768374096,\n",
       " -0.1902053875005328,\n",
       " 0.5433423409868958,\n",
       " 0.004785062868595832,\n",
       " 0.10830331743866146,\n",
       " 0.829346520287552,\n",
       " 0.7272523039110871,\n",
       " 0.8526552736717857,\n",
       " -0.11884179598186957,\n",
       " 0.48669132774274176,\n",
       " 0.7666947725201139,\n",
       " 0.0017598261046671572,\n",
       " 0.2025200861550257,\n",
       " 0.22272472860352618,\n",
       " 0.7229899667910076,\n",
       " 0.3455495874914367,\n",
       " 0.18210768950876458,\n",
       " 0.7455115916332207,\n",
       " -0.1073701609487923,\n",
       " 0.3922955883499569,\n",
       " 0.15725685548474735,\n",
       " 0.22483275740250433,\n",
       " 0.4291056920775265,\n",
       " 0.3580990156500072,\n",
       " -0.0008632375813860498,\n",
       " -0.11582657799842416,\n",
       " -0.22629492288445863,\n",
       " 0.6736438308241003,\n",
       " 0.7348327043791277,\n",
       " 0.47961435908443645,\n",
       " 0.701189485262083,\n",
       " 0.08186370870112852,\n",
       " 0.4652036952658298,\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6baad4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27afdbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x145bcd9cd130>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 288,
       "width": 317
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e99555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new.var['pval'] = pval_list\n",
    "adata_new.var['cor'] = cor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b17e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new.write_h5ad(\"spatial_imputation_zeroshots.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d25ac71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 324 × 11968\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster', 'batch', 'celltype', 'str_batch', 'batch_id'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'gene_name', 'id_in_vocab', 'n_counts', 'pval', 'cor'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c237cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04585cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76ade565",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new.write_h5ad(\"spatial_impuration.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.scale(adata_new) \n",
    "sc.tl.pca(adata_new)\n",
    "sc.pp.neighbors(adata_new)\n",
    "sc.tl.umap(adata_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}