{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8b24aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de351b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78e1b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "adata = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/scGPT/examples/predict_dosage_dataset.h5ad\")\n",
    "adata = sc.AnnData(adata.X, obs = adata.obs, var = adata.var)\n",
    "adata.obs['celltype'] = ['no' for i in adata.obs_names]\n",
    "adata.obs['batch'] = ['no' for i in adata.obs_names]\n",
    "\n",
    "# adata = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/scGPT/gene_labels/task3a_bi_nom.h5ad\")\n",
    "# adata = sc.AnnData(adata.X, obs = adata.obs, var = adata.var)\n",
    "# adata.obs['celltype'] = ['no' for i in adata.obs_names]\n",
    "# adata.obs['batch'] = ['no' for i in adata.obs_names]\n",
    "\n",
    "# adata = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/scGPT/gene_labels/task3b_bi_lys4.h5ad\")\n",
    "# print(adata.var_names)\n",
    "# adata = sc.AnnData(adata.X, obs = adata.obs, var = adata.var)\n",
    "# adata.obs['celltype'] = ['no' for i in adata.obs_names]\n",
    "# adata.obs['batch'] = ['no' for i in adata.obs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "496b9004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['7SK', 'A1BG-AS1', 'A1BG', 'A1CF', 'A2M-AS1', 'A2M', 'A2ML1', 'A2MP1',\n",
       "       'A4GALT', 'AAAS',\n",
       "       ...\n",
       "       'ZW10', 'ZWILCH', 'ZWINT', 'ZXDB', 'ZXDC', 'ZYG11A', 'ZYG11B', 'ZYX',\n",
       "       'ZZEF1', 'ZZZ3'],\n",
       "      dtype='object', length=26674)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e655251",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train = adata[:, adata.var['dose_cond'] != -1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "67998069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31ea33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_gene_labels,\n",
    "    valid_gene_labels,\n",
    "    train_gene_name,\n",
    "    valid_gene_name,\n",
    "    train_adata_varnames,\n",
    "    valid_adata_varnames\n",
    "    \n",
    ") = train_test_split(\n",
    "    adata_train.X.T, adata_train.var['dose_cond'], adata_train.var_names, adata_train.var_names, test_size=0.33, shuffle=True, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ddf2e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RARB       1\n",
       "ZNF33B     0\n",
       "ZKSCAN8    0\n",
       "ZNF684     0\n",
       "ZNF22      0\n",
       "          ..\n",
       "MBD2       1\n",
       "PRDM16     1\n",
       "ZNF439     0\n",
       "ZNF664     0\n",
       "PAX8       1\n",
       "Name: dose_cond, Length: 289, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gene_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df5deacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RARB', 'ZNF33B', 'ZKSCAN8', 'ZNF684', 'ZNF22', 'MYCN', 'ZNF625',\n",
       "       'ZNF480', 'MECOM', 'ZNF154',\n",
       "       ...\n",
       "       'ZNF20', 'RUNX2', 'ZUFSP', 'DLX1', 'ZFP41', 'MBD2', 'PRDM16', 'ZNF439',\n",
       "       'ZNF664', 'PAX8'],\n",
       "      dtype='object', length=289)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gene_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9fc081ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geneemb = pd.read_csv(\"../cellfm_pathwayenrichment.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8071fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovarlap_train = sorted(set(train_gene_name).intersection(set(df_geneemb.index)))\n",
    "df_geneemb_train = df_geneemb.loc[ovarlap_train]\n",
    "y_train = train_gene_labels.loc[ovarlap_train].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d07d33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovarlap_valid = sorted(set(valid_gene_name).intersection(set(df_geneemb.index)))\n",
    "df_geneemb_valid = df_geneemb.loc[ovarlap_valid]\n",
    "y_valid = valid_gene_labels.loc[ovarlap_valid].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039b470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "80995c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A simple dummy dataset for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, data,label):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        # Create random labels (0 or 1)\n",
    "        self.labels = torch.FloatTensor(label).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class DummyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, emb_dims=128):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.emb_dims = emb_dims\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        self.train_dataset, self.val_dataset =DummyDataset(df_geneemb_train.values,y_train), DummyDataset(df_geneemb_valid.values,y_valid)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "\n",
    "# --- 2. Define the Lightning Module (ClassifierModel) ---\n",
    "\n",
    "class ClassifierModel(pl.LightningModule):\n",
    "    def __init__(self, emb_dims=128, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        # Saves emb_dims and learning_rate to self.hparams for easy access\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Translate the MindSpore architecture to PyTorch:\n",
    "        # nn.Dense(emb_dims, emb_dims//2, has_bias=False) -> nn.Linear(emb_dims, emb_dims//2, bias=False)\n",
    "        # nn.SiLU() is directly available in PyTorch\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            # Layer 1: emb_dims -> emb_dims//2\n",
    "            nn.Linear(emb_dims, emb_dims // 2, bias=False),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.SiLU(),\n",
    "\n",
    "            # Layer 2: emb_dims//2 -> emb_dims//4\n",
    "            nn.Linear(emb_dims // 2, emb_dims // 4, bias=False),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.SiLU(),\n",
    "\n",
    "            # Layer 3: emb_dims//4 -> 2 (2 classes)\n",
    "            nn.Linear(emb_dims // 4, 2, bias=False),\n",
    "        )\n",
    "\n",
    "        # Loss function for classification\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Passes the input tensor through the MLP.\"\"\"\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        \"\"\"Reusable function for training and validation steps.\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        n_correct = (preds == y).sum().item()\n",
    "        n_total = y.size(0)\n",
    "        \n",
    "        return loss, n_correct, n_total\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, n_correct, n_total = self._common_step(batch, batch_idx)\n",
    "        acc = n_correct / n_total\n",
    "        \n",
    "        # Logging to the progress bar and logger\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, n_correct, n_total = self._common_step(batch, batch_idx)\n",
    "        \n",
    "        # Logging validation metrics\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_n_correct', float(n_correct), on_step=False, on_epoch=True, reduce_fx='sum')\n",
    "        self.log('val_n_total', float(n_total), on_step=False, on_epoch=True, reduce_fx='sum')\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        # Calculate final validation accuracy after all steps\n",
    "        n_correct = self.trainer.logged_metrics['val_n_correct']\n",
    "        n_total = self.trainer.logged_metrics['val_n_total']\n",
    "        val_acc = n_correct / n_total\n",
    "        self.log('val_acc', val_acc, prog_bar=True)\n",
    "        del self.trainer.logged_metrics['val_n_correct']\n",
    "        del self.trainer.logged_metrics['val_n_total']\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Defines the optimizer.\"\"\"\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "93280bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b045e7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.8 /gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/l ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | mlp     | Sequential       | 1.5 M \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.901     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with emb_dims=1536, LR=0.0001, Epochs=30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8030a597164c4687571b846800a6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at lightning_logs/mlp_classifier/version_8/checkpoints/epoch=29-step=150.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at lightning_logs/mlp_classifier/version_8/checkpoints/epoch=29-step=150.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training complete. Running validation on best model ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bcdf40816a4f9a99e6279ba012fc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6788321137428284     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5864219665527344     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_n_correct       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           93.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_n_total        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           137.0           </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6788321137428284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5864219665527344    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_n_correct      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          93.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_n_total       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          137.0          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.5864219665527344,\n",
       "  'val_n_correct': 93.0,\n",
       "  'val_n_total': 137.0,\n",
       "  'val_acc': 0.6788321137428284}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "EMB_DIMS = 1536  # Must match the input feature size\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_EPOCHS = 30\n",
    "\n",
    "print(f\"Starting training with emb_dims={EMB_DIMS}, LR={LEARNING_RATE}, Epochs={MAX_EPOCHS}\")\n",
    "\n",
    "# 1. Setup DataModule\n",
    "dm = DummyDataModule(batch_size=BATCH_SIZE, emb_dims=EMB_DIMS)\n",
    "\n",
    "# 2. Setup Model\n",
    "model = ClassifierModel(emb_dims=EMB_DIMS, learning_rate=LEARNING_RATE)\n",
    "\n",
    "# 3. Setup Logger and Trainer\n",
    "# Use CSVLogger to save logs in 'lightning_logs/'\n",
    "logger = CSVLogger(\"lightning_logs\", name=\"mlp_classifier\")\n",
    "\n",
    "# Check for GPU availability\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=logger,\n",
    "    accelerator=accelerator,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# 4. Train the Model\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# 5. Optional: Test the model after training\n",
    "print(\"\\n--- Training complete. Running validation on best model ---\")\n",
    "trainer.validate(ckpt_path=\"best\", datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c8e2cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.cuda()\n",
    "    y_pred = model(torch.FloatTensor(df_geneemb_valid.values).cuda()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f36b3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "086e9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = y_pred.argmax(axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9dac2775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9485    0.7023    0.8070       131\n",
      "           1     0.0250    0.1667    0.0435         6\n",
      "\n",
      "    accuracy                         0.6788       137\n",
      "   macro avg     0.4867    0.4345    0.4252       137\n",
      "weighted avg     0.9080    0.6788    0.7736       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label, y_valid, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fcdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e52202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22edea2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
